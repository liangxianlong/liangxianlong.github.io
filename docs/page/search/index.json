[{"content":"内核版本linux-5.10.194\nkvmtool: http://git.kernel.org/pub/scm/linux/kernel/git/will/kvmtool.git\n对于虚拟化的学习，本系列以linux-5.10.194以及kvmtool为工具。\nKVM初始化 初始化KVM时，需要加载kvm.ko以及kvm-intel.ko两个内核模块。其中kvm.ko由KVM的通用代码生成，kvm-intel.ko是由Intel CPU架构相关代码生成。最终kvmtool和kvm的交互由kvm.ko导出的设备/dev/kvm完成。\n整个KVM的初始化由函数vmx_init来完成，其主要调用了kvm_init函数。\n1 2 3 4 5 6 7 8 static int __init vmx_init(void) { int r, cpu; r = kvm_init(\u0026amp;vmx_init_ops, sizeof(struct vcpu_vmx), __alignof__(struct vcpu_vmx), THIS_MODULE); ... return 0; } 函数kvm_init中的vmx_init_ops参数表示Intel VT-x实现的各种回调函数:\n1 2 3 4 5 6 7 8 9 static struct kvm_x86_init_ops vmx_init_ops __initdata = { .cpu_has_kvm_support = cpu_has_kvm_support, .disabled_by_bios = vmx_disabled_by_bios, .check_processor_compatibility = vmx_check_processor_compat, .hardware_setup = hardware_setup, .handle_intel_pt_intr = NULL, .runtime_ops = \u0026amp;vmx_x86_ops, }; vmx_init_ops中内嵌变量runtime_ops由vmx_x86_ops指定。可以看到vmx_x86_ops才是真正的Intel VT-x回调函数集合：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 static struct kvm_x86_ops vmx_x86_ops __initdata = { .name = \u0026#34;kvm_intel\u0026#34;, .hardware_unsetup = hardware_unsetup, .hardware_enable = hardware_enable, .hardware_disable = hardware_disable, .cpu_has_accelerated_tpr = report_flexpriority, .has_emulated_msr = vmx_has_emulated_msr, .vm_size = sizeof(struct kvm_vmx), .vm_init = vmx_vm_init, .vcpu_create = vmx_create_vcpu, .vcpu_free = vmx_free_vcpu, .vcpu_reset = vmx_vcpu_reset, .prepare_guest_switch = vmx_prepare_switch_to_guest, .vcpu_load = vmx_vcpu_load, .vcpu_put = vmx_vcpu_put, .update_exception_bitmap = vmx_update_exception_bitmap, .get_msr_feature = vmx_get_msr_feature, .get_msr = vmx_get_msr, .set_msr = vmx_set_msr, .get_segment_base = vmx_get_segment_base, .get_segment = vmx_get_segment, .set_segment = vmx_set_segment, .get_cpl = vmx_get_cpl, .get_cs_db_l_bits = vmx_get_cs_db_l_bits, .set_cr0 = vmx_set_cr0, .is_valid_cr4 = vmx_is_valid_cr4, .set_cr4 = vmx_set_cr4, .set_efer = vmx_set_efer, .get_idt = vmx_get_idt, .set_idt = vmx_set_idt, .get_gdt = vmx_get_gdt, .set_gdt = vmx_set_gdt, .set_dr7 = vmx_set_dr7, .sync_dirty_debug_regs = vmx_sync_dirty_debug_regs, .cache_reg = vmx_cache_reg, .get_rflags = vmx_get_rflags, .set_rflags = vmx_set_rflags, .get_if_flag = vmx_get_if_flag, .tlb_flush_all = vmx_flush_tlb_all, .tlb_flush_current = vmx_flush_tlb_current, .tlb_flush_gva = vmx_flush_tlb_gva, .tlb_flush_guest = vmx_flush_tlb_guest, .vcpu_pre_run = vmx_vcpu_pre_run, .run = vmx_vcpu_run, .handle_exit = vmx_handle_exit, .skip_emulated_instruction = vmx_skip_emulated_instruction, .update_emulated_instruction = vmx_update_emulated_instruction, .set_interrupt_shadow = vmx_set_interrupt_shadow, .get_interrupt_shadow = vmx_get_interrupt_shadow, .patch_hypercall = vmx_patch_hypercall, .set_irq = vmx_inject_irq, .set_nmi = vmx_inject_nmi, .queue_exception = vmx_queue_exception, .cancel_injection = vmx_cancel_injection, .interrupt_allowed = vmx_interrupt_allowed, .nmi_allowed = vmx_nmi_allowed, .get_nmi_mask = vmx_get_nmi_mask, .set_nmi_mask = vmx_set_nmi_mask, .enable_nmi_window = vmx_enable_nmi_window, .enable_irq_window = vmx_enable_irq_window, .update_cr8_intercept = vmx_update_cr8_intercept, .set_virtual_apic_mode = vmx_set_virtual_apic_mode, .set_apic_access_page_addr = vmx_set_apic_access_page_addr, .refresh_apicv_exec_ctrl = vmx_refresh_apicv_exec_ctrl, .load_eoi_exitmap = vmx_load_eoi_exitmap, .apicv_post_state_restore = vmx_apicv_post_state_restore, .check_apicv_inhibit_reasons = vmx_check_apicv_inhibit_reasons, .hwapic_irr_update = vmx_hwapic_irr_update, .hwapic_isr_update = vmx_hwapic_isr_update, .guest_apic_has_interrupt = vmx_guest_apic_has_interrupt, .sync_pir_to_irr = vmx_sync_pir_to_irr, .deliver_interrupt = vmx_deliver_interrupt, .dy_apicv_has_pending_interrupt = pi_has_pending_interrupt, .set_tss_addr = vmx_set_tss_addr, .set_identity_map_addr = vmx_set_identity_map_addr, .get_mt_mask = vmx_get_mt_mask, .get_exit_info = vmx_get_exit_info, .vcpu_after_set_cpuid = vmx_vcpu_after_set_cpuid, .has_wbinvd_exit = cpu_has_vmx_wbinvd_exit, .get_l2_tsc_offset = vmx_get_l2_tsc_offset, .get_l2_tsc_multiplier = vmx_get_l2_tsc_multiplier, .write_tsc_offset = vmx_write_tsc_offset, .write_tsc_multiplier = vmx_write_tsc_multiplier, .load_mmu_pgd = vmx_load_mmu_pgd, .check_intercept = vmx_check_intercept, .handle_exit_irqoff = vmx_handle_exit_irqoff, .request_immediate_exit = vmx_request_immediate_exit, .sched_in = vmx_sched_in, .cpu_dirty_log_size = PML_ENTITY_NUM, .update_cpu_dirty_logging = vmx_update_cpu_dirty_logging, .pmu_ops = \u0026amp;intel_pmu_ops, .nested_ops = \u0026amp;vmx_nested_ops, .update_pi_irte = pi_update_irte, .start_assignment = vmx_pi_start_assignment, #ifdef CONFIG_X86_64 .set_hv_timer = vmx_set_hv_timer, .cancel_hv_timer = vmx_cancel_hv_timer, #endif .setup_mce = vmx_setup_mce, .smi_allowed = vmx_smi_allowed, .enter_smm = vmx_enter_smm, .leave_smm = vmx_leave_smm, .enable_smi_window = vmx_enable_smi_window, .can_emulate_instruction = vmx_can_emulate_instruction, .apic_init_signal_blocked = vmx_apic_init_signal_blocked, .migrate_timers = vmx_migrate_timers, .msr_filter_changed = vmx_msr_filter_changed, .complete_emulated_msr = kvm_complete_insn_gp, .vcpu_deliver_sipi_vector = kvm_vcpu_deliver_sipi_vector, }; 如下图所示以kvm_init为中心的函数调用图：\n函数说明\nkvm_arch_init:\ncpu_has_kvm_support和disabled_by_bios:检测逻辑cpu是否支持VMX操作，以及是否被Bios关闭。\nkvm_mmu_vendor_module_init:内存虚拟化初始化。\nkvm_timer_init:时间虚拟化初始化。\nkvm_arch_hardware_setup:\nset_vmcs_config根据当前逻辑cpu创建一个全局的vmcs_config用于与后续的每一个逻辑cpu的vmcs_conf做比较，若不一致则退出KVM初始化流程。 cpu_has_vmx_ept和cpu_has_vmx_apicv:根据vmcs_config和MSR值来设置某些全局变量，比如是否支持EPT的enable_ept变量()。 kvm_configure_mmu:根据全局变量enable_ept设置全局变量tdp_enabled以及max_huge_page_level。 alloc_kvm_area():分配vmxon区域，并且放到vmxarea这个percpu变量中。 check_processor_compat:检测所有的逻辑cpu的vmcs是否一致。\nmisc_register:注册misc设备/deev/kvm。\n1 2 3 4 5 6 7 8 9 10 11 r = misc_register(\u0026amp;kvm_dev); static struct miscdevice kvm_dev = { KVM_MINOR, \u0026#34;kvm\u0026#34;, \u0026amp;kvm_chardev_ops, }; static struct file_operations kvm_chardev_ops = { .unlocked_ioctl = kvm_dev_ioctl, .llseek = noop_llseek, KVM_COMPAT(kvm_dev_ioctl), }; 通过misc_register(\u0026amp;kvm_dev)就注册了misc设备/dev/kvm，可以看到/dev/kvm只支持ioctl系统调用。\nkvm_dev_ioctl代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 static long kvm_dev_ioctl(struct file *filp, unsigned int ioctl, unsigned long arg) { long r = -EINVAL; switch (ioctl) { case KVM_GET_API_VERSION: if (arg) goto out; r = KVM_API_VERSION; break; case KVM_CREATE_VM: r = kvm_dev_ioctl_create_vm(arg); break; case KVM_CHECK_EXTENSION: r = kvm_vm_ioctl_check_extension_generic(NULL, arg); break; case KVM_GET_VCPU_MMAP_SIZE: if (arg) goto out; r = PAGE_SIZE; /* struct kvm_run */ #ifdef CONFIG_X86 r += PAGE_SIZE; /* pio data page */ #endif #ifdef CONFIG_KVM_MMIO r += PAGE_SIZE; /* coalesced mmio ring page */ #endif break; case KVM_TRACE_ENABLE: case KVM_TRACE_PAUSE: case KVM_TRACE_DISABLE: r = -EOPNOTSUPP; break; default: return kvm_arch_dev_ioctl(filp, ioctl, arg); } out: return r; } 从上述代码可以看到/dev/kvm的ioctl接口分为两类：\n通用接口:比如KVM_API_VERSION和KVM_CREATE_VM。\n架构相关接口:kvm_arch_dev_ioctl。\n此外，参见如下图，整个KVM还包括VM层面的ioctl以及VCPU层面的ioctl。\nKVM的初始化流程没有使逻辑cpu进入VMX模式，因为在整个vmx_init流程中并没有将CR4.VMXE[bit 13]设置为1。VMX模式的开启是在创建第一个虚拟机的时候。\n虚拟机的创建 创建KVM虚拟机需要用户态的kvmtool发起。在kvmtool代码中，创建KVM虚拟机的流程由kvm__init发起。kvmtool和kvm的交互如下图所示:\nkvmtool 打开/dev/kvm设备文件，获取此设备文件的fd。\n根据1.中的fd，发起KVM_CREATE_VM调用，请求kvm创建虚拟机。代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 int kvm__init(struct kvm *kvm) { int ret; // kvm__arch_cpu_supports_vm: 使用cpuid指令检测硬件环境是否支持虚拟化 if (!kvm__arch_cpu_supports_vm()) { pr_err(\u0026#34;Your CPU does not support hardware virtualization\u0026#34;); ret = -ENOSYS; goto err; } // open /dev/kvm kvm-\u0026gt;sys_fd = open(kvm-\u0026gt;cfg.dev, O_RDWR); ... // KVM_GET_API_VERSION: Get the API version as the stable kvm API ret = ioctl(kvm-\u0026gt;sys_fd, KVM_GET_API_VERSION, 0); ... // KVM_CREATE_VM: 创建虚拟机 kvm-\u0026gt;vm_fd = ioctl(kvm-\u0026gt;sys_fd, KVM_CREATE_VM, kvm__get_vm_type(kvm)); ... // query about extensions to the core kvm API. if (kvm__check_extensions(kvm)) { pr_err(\u0026#34;A required KVM extension is not supported by OS\u0026#34;); ret = -ENOSYS; goto err_vm_fd; } kvm__arch_init(kvm); ... } kvm 在内核KVM模块中，函数kvm_dev_ioctl根据kvmtool发起ioctl调用时传入的KVM_CREATE_VM最终调用到kvm_dev_ioctl_create_vm函数，\nkvm_create_vm:创建虚拟机的核心函数。\nkvm_coalesced_mmio_init``:对``coalesced MMIO进行初始化。其实就是分配了一个struct page，然后将此page所在的虚拟地址赋值给kvm-\u0026gt;coalesced_mmio_ring。\nget_unused_fd_flags:获取一个未被使用的fd，此fd作为VM层面调用ioctl时的fd。\nanon_inode_getfile:创建一个匿名的文件实例。\nfd_install:将get_unused_fd_flags获取的fd和anon_inode_getfile创建的匿名文件实例关联起来。\nkvm_create_vm 作为创建虚拟机核心函数，kvm_create_vm调用关系如下:\n精简后的代码如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 static struct kvm *kvm_create_vm(unsigned long type) { struct kvm *kvm = kvm_arch_alloc_vm(); struct kvm_memslots *slots; int r = -ENOMEM; int i, j; ... mmgrab(current-\u0026gt;mm); kvm-\u0026gt;mm = current-\u0026gt;mm; kvm_eventfd_init(kvm); ... xa_init(\u0026amp;kvm-\u0026gt;vcpu_array); ... refcount_set(\u0026amp;kvm-\u0026gt;users_count, 1); for (i = 0; i \u0026lt; KVM_ADDRESS_SPACE_NUM; i++) { for (j = 0; j \u0026lt; 2; j++) { slots = \u0026amp;kvm-\u0026gt;__memslots[i][j]; atomic_long_set(\u0026amp;slots-\u0026gt;last_used_slot, (unsigned long)NULL); slots-\u0026gt;hva_tree = RB_ROOT_CACHED; slots-\u0026gt;gfn_tree = RB_ROOT; hash_init(slots-\u0026gt;id_hash); slots-\u0026gt;node_idx = j; /* Generations must be different for each address space. */ slots-\u0026gt;generation = i; } rcu_assign_pointer(kvm-\u0026gt;memslots[i], \u0026amp;kvm-\u0026gt;__memslots[i][0]); } for (i = 0; i \u0026lt; KVM_NR_BUSES; i++) { rcu_assign_pointer(kvm-\u0026gt;buses[i], kzalloc(sizeof(struct kvm_io_bus), GFP_KERNEL_ACCOUNT)); if (!kvm-\u0026gt;buses[i]) goto out_err_no_arch_destroy_vm; } kvm-\u0026gt;max_halt_poll_ns = halt_poll_ns; r = kvm_arch_init_vm(kvm, type); ... r = hardware_enable_all(); ... #ifdef CONFIG_HAVE_KVM_IRQFD INIT_HLIST_HEAD(\u0026amp;kvm-\u0026gt;irq_ack_notifier_list); #endif r = kvm_init_mmu_notifier(kvm); ... r = kvm_arch_post_init_vm(kvm); ... list_add(\u0026amp;kvm-\u0026gt;vm_list, \u0026amp;vm_list); preempt_notifier_inc(); kvm_init_pm_notifier(kvm); /* * When the fd passed to this ioctl() is opened it pins the module, * but try_module_get() also prevents getting a reference if the module * is in MODULE_STATE_GOING (e.g. if someone ran \u0026#34;rmmod --wait\u0026#34;). */ if (!try_module_get(kvm_chardev_ops.owner)) { r = -ENODEV; goto out_err; } return kvm; out_err: ... return ERR_PTR(r); } kvm_arch_alloc_vm:分配一个struct kvm指针，用于表示一台虚拟机。\nkvm_arch_init_vm:初始化struct kvm-\u0026gt;arch变量。\nhardware_enable_all:设置CR4.VMXE[bit 13] = 1使能VMX模式；对每一个逻辑cpu调用vmxon指令使其进入VMX模式。\nlist_add(\u0026amp;kvm-\u0026gt;vm_list, \u0026amp;vm_list):将kvm-\u0026gt;vm_list挂到以vm_list为头节点的链表上。\nvCPU的创建 虚拟机创建完成后，kvmtool可以根据其调用KVM_CREATE_VM时返回的虚拟机fd发起新的ioctl调用，请求创建vCPU。在kvmtool中，每一个vCPU对应宿主机操作系统中的一个用户态线程。在创建单个vCPU时，kvmtool和kvm的交互如下图。\n图中kvmtool侧vcpu-\u0026gt;kvm-\u0026gt;vmfd就是虚拟机的创建中由KVM_CREATE_VM返回的虚拟机fd。虚拟机fd所关联的匿名文件file_operations在kvm中定义如下：\n1 2 3 4 5 6 static struct file_operations kvm_vm_fops = { .release = kvm_vm_release, .unlocked_ioctl = kvm_vm_ioctl, .llseek = noop_llseek, KVM_COMPAT(kvm_vm_compat_ioctl), }; kvm侧函数简介:\nvcpu = kmem_cache_zalloc:分配struct kvm_vcpu指针变量，此变量是一个kvm_vcpu_cache。\nkvm_vcpu_init(vcpu, kvm, id):初始化由kmem_cache_zalloc分配的指针变量，将虚拟机所属的struct kvm变量和其关联(vcpu-\u0026gt;kvm = kvm )。\nkvm_arch_vcpu_create(vcpu):此函数是创建vCPU的核心函数之一，其最终调用了vmx_x86_ops中注册的vmx_create_vcpu函数。\nkvm_get_kvm(kvm):每创建一个vCPU就将该虚拟机对应的kvm-\u0026gt;users_count加1。\ncreate_vcpu_fd(vcpu):为新创建的vcpu关联一个匿名文件并且返回此匿名文件的文件描述符作为当前vcpu的fd，此fd返回给kvmtool使用；fd所关联的file_operations为kvm_vcpu_fops。\nkvm_arch_vcpu_postcreate(vcpu): 分别调用vmx_vcpu_load和vmx_vcpu_put。\nkvm 由于在创建vcpu时，kvmtool侧只需调用KVM_CREATE_VCPU即可。因此接下来重点分析kvm侧的代码。kvm侧代码参考如下图: kvm_arch_vcpu_create 从上图可以看到，kvm侧创建vCPU时kvm_arch_vcpu_create扮演了及其重要的角色:\n调用vmx_create_vcpu函数:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 static int vmx_create_vcpu(struct kvm_vcpu *vcpu) { struct vmx_uret_msr *tsx_ctrl; struct vcpu_vmx *vmx; int i, err; ... vmx = to_vmx(vcpu); INIT_LIST_HEAD(\u0026amp;vmx-\u0026gt;pi_wakeup_list); vmx-\u0026gt;vpid = allocate_vpid(); ... err = alloc_loaded_vmcs(\u0026amp;vmx-\u0026gt;vmcs01); ... vmx-\u0026gt;loaded_vmcs = \u0026amp;vmx-\u0026gt;vmcs01; ... return 0; ... free_vpid: free_vpid(vmx-\u0026gt;vpid); return err; } 调用alloc_loaded_vmcs分配struct vmcs结构。将新分配的vmcs所关联的逻辑cpu字段设置为-1(loaded_vmcs-\u0026gt;cpu = -1)，表示此vmcs未绑定到任何逻辑cpu；将新分配的vmcs所关联的launche设置为0表示此vmcs为非launched，后续VM entry应该使用VMLAUNCH指令，若loaded_vmcs-\u0026gt;launched == 1，后续VM entry应该使用VMRESUME指令。\n1 2 3 4 5 6 7 8 9 10 int alloc_loaded_vmcs(struct loaded_vmcs *loaded_vmcs) { loaded_vmcs-\u0026gt;vmcs = alloc_vmcs(false); ...; vmcs_clear(loaded_vmcs-\u0026gt;vmcs); ...; loaded_vmcs-\u0026gt;cpu = -1; loaded_vmcs-\u0026gt;launched = 0; ... } struct loaded_vmcs定义如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /* * Track a VMCS that may be loaded on a certain CPU. If it is (cpu!=-1), also * remember whether it was VMLAUNCHed, and maintain a linked list of all VMCSs * loaded on this CPU (so we can clear them if the CPU goes down). */ struct loaded_vmcs { struct vmcs *vmcs; struct vmcs *shadow_vmcs; int cpu; bool launched; bool nmi_known_unmasked; bool hv_timer_soft_disabled; /* Support for vnmi-less CPUs */ int soft_vnmi_blocked; ktime_t entry_time; s64 vnmi_blocked_time; unsigned long *msr_bitmap; struct list_head loaded_vmcss_on_cpu_link; struct vmcs_host_state host_state; struct vmcs_controls_shadow controls_shadow; }; struct vmcs定义如下:\n1 2 3 4 5 struct vmcs { struct vmcs_hdr hdr; u32 abort; char data[]; }; struct vmcs_hdr:\n1 2 3 4 struct vmcs_hdr { u32 revision_id:31; u32 shadow_vmcs:1; }; 根据Intel SDM描述:\nvmcs.vmcs_hdr.revision_id表示VMCS revision标识符，占用第一个4字节数据的0-30位。 vmcs.vmcs_hdr.shadow_vmcs占用第一个4字节数据的第31位，指示当前vmcs是否为shadow-VMCS。 vmcs.abort完全占用第二个4字节数据，表示VMX中止指示，VM-Exit执行不成功时产生VMX中止，CPU会在此处存入VMX中止的原因，以方便调试。 vmcs.data为vmcs的数据域，此字段中的数据是特定于cpu的。 在非嵌套虚拟化环境下，将vmx-\u0026gt;loaded_vmcs设置为\u0026amp;vmx-\u0026gt;vmcs01，参考如下说明:\n​\t/*\n​ ** loaded_vmcs points to the VMCS currently used in this vcpu. For a*\n​ ** non-nested (L1) guest, it always points to vmcs01. For a nested*\n​ ** guest (L2), it points to a different VMCS.*\n​ */\n经由vcpu_load(vcpu)调用vmx_vcpu_load(struct kvm_vcpu *vcpu, int cpu)，最后调用vmx_vcpu_load_vmcs(*vcpu*, *cpu*, NULL)中的vmcs_load函数将vmcs与当前逻辑cpu绑定。如下函数逻辑见代码中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 void vmx_vcpu_load_vmcs(struct kvm_vcpu *vcpu, int cpu, struct loaded_vmcs *buddy) { struct vcpu_vmx *vmx = to_vmx(vcpu); /* * vmcs关联的逻辑cpu是否是当前逻辑cpu,以此作为vmcs是否已经loaded的依据 */ bool already_loaded = vmx-\u0026gt;loaded_vmcs-\u0026gt;cpu == cpu; struct vmcs *prev; /* * vmcs未被loaded */ if (!already_loaded) { loaded_vmcs_clear(vmx-\u0026gt;loaded_vmcs); local_irq_disable(); /* * Ensure loaded_vmcs-\u0026gt;cpu is read before adding loaded_vmcs to * this cpu\u0026#39;s percpu list, otherwise it may not yet be deleted * from its previous cpu\u0026#39;s percpu list. Pairs with the * smb_wmb() in __loaded_vmcs_clear(). */ smp_rmb(); /* * 将vmx-\u0026gt;loaded_vmcs添加到当前逻辑cpu的loaded_vmcss_on_cpu链表上 */ list_add(\u0026amp;vmx-\u0026gt;loaded_vmcs-\u0026gt;loaded_vmcss_on_cpu_link, \u0026amp;per_cpu(loaded_vmcss_on_cpu, cpu)); local_irq_enable(); } /* * 取出当前逻辑cpu的current_vmcs与vmx-\u0026gt;loaded_vmcs-\u0026gt;vmcs做比较 * 若不相等，表示需要更新当前逻辑cpu的current_vmcs * 然后使用vmptrld指令将vmx-\u0026gt;loaded_vmcs-\u0026gt;vmcs与当前逻辑cpu绑定 */ prev = per_cpu(current_vmcs, cpu); if (prev != vmx-\u0026gt;loaded_vmcs-\u0026gt;vmcs) { per_cpu(current_vmcs, cpu) = vmx-\u0026gt;loaded_vmcs-\u0026gt;vmcs; vmcs_load(vmx-\u0026gt;loaded_vmcs-\u0026gt;vmcs); ... } if (!already_loaded) { ...; /* * 将vmx-\u0026gt;loaded_vmcs所关联的逻辑cpu设置为当前逻辑cpu */ vmx-\u0026gt;loaded_vmcs-\u0026gt;cpu = cpu; } } kvm_vcpu_reset(vcpu, false)最终调用vmx_vcpu_reset，vmx_set_cr0，vmx_set_cr4，vmx_set_eferr，vmx_update_exception_bitmap设置vmcs中data域的值。设置vmcs时，由函数vmcs_writeX执行vmwrite指令写相关的域。\nkvm_get_kvm kvm_get_kvm函数将struct kvm中的成员变量users_count原子的加1，表示引用此struct kvm的成员数量。\n1 2 3 4 5 void kvm_get_kvm(struct kvm *kvm) { refcount_inc(\u0026amp;kvm-\u0026gt;users_count); } EXPORT_SYMBOL_GPL(kvm_get_kvm); 在调用kvm_put_kvm函数时，首先检测kvm-\u0026gt;users_count是否为0，若为0则销毁虚拟机。代码参见如下:\n1 2 3 4 5 6 void kvm_put_kvm(struct kvm *kvm) { if (refcount_dec_and_test(\u0026amp;kvm-\u0026gt;users_count)) kvm_destroy_vm(kvm); } EXPORT_SYMBOL_GPL(kvm_put_kvm); create_vcpu_fd 为新创建的vcpu关联一个匿名文件并且返回此匿名文件的文件描述符作为当前vcpu-fd，此vcpu-fd返回给kvmtool使用。\n1 2 3 4 5 6 7 8 9 10 /* * Allocates an inode for the vcpu. */ static int create_vcpu_fd(struct kvm_vcpu *vcpu) { char name[8 + 1 + ITOA_MAX_LEN + 1]; snprintf(name, sizeof(name), \u0026#34;kvm-vcpu:%d\u0026#34;, vcpu-\u0026gt;vcpu_id); return anon_inode_getfd(name, \u0026amp;kvm_vcpu_fops, vcpu, O_RDWR | O_CLOEXEC); } vcpu-fd所关联的file_operations为kvm_vcpu_fops:\n1 2 3 4 5 6 7 static struct file_operations kvm_vcpu_fops = { .release = kvm_vcpu_release, .unlocked_ioctl = kvm_vcpu_ioctl, .mmap = kvm_vcpu_mmap, .llseek = noop_llseek, KVM_COMPAT(kvm_vcpu_compat_ioctl), }; kvm_arch_vcpu_postcreate 根据代码看，kvm_arch_vcpu_postcreate最终调用了vmx_vcpu_load以及vmx_vcpu_put。根据之前kvm_arch_vcpu_create流程分析，此时在kvm_arch_vcpu_postcreate中调用vmx_vcpu_load和vmx_vcpu_put的作用不是太清楚。\n至此，整个KVM_CREATE_VCPU的流程就分析完毕了。\nkvmtool与kvm之间的共享数据 在执行KVM_RUN调用之前，kvmtool与kvm需要分配一块共享内存用于共享数据。首先，kvmtool调用KVM_GET_VCPU_MMAP_SIZE获取此共享内存的大小，然后使用mmap在kvmtool进程的虚拟地址空间创建一个新的映射。代码参考如下:\n1 2 3 mmap_size = ioctl(vcpu-\u0026gt;kvm-\u0026gt;sys_fd, KVM_GET_VCPU_MMAP_SIZE, 0); ...; vcpu-\u0026gt;kvm_run = mmap(NULL, mmap_size, PROT_RW, MAP_SHARED, vcpu-\u0026gt;vcpu_fd, 0); kvm 从kvmtool代码可以看到，KVM_GET_VCPU_MMAP_SIZE在调用ioctl时使用的文件描述符为kvm-fd，因此其入口是kvm_dev_ioctl。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 static long kvm_dev_ioctl(struct file *filp, unsigned int ioctl, unsigned long arg) { long r = -EINVAL; switch (ioctl) { ...; case KVM_GET_VCPU_MMAP_SIZE: if (arg) goto out; r = PAGE_SIZE; /* struct kvm_run */ #ifdef CONFIG_X86 r += PAGE_SIZE; /* pio data page */ #endif #ifdef CONFIG_KVM_MMIO r += PAGE_SIZE; /* coalesced mmio ring page */ #endif break; ...; 上述代码说明在kvmtool在调用KVM_GET_VCPU_MMAP_SIZE后mmap_size的大小最小为1个PAGE_SIZE，最多为3个PAGE_SIZE。第一个页面用于struct kvm_run，第二个页面用于pio data page，第三个页面用于coalesced mmio ring page。具体的大小与CONFIG_X86以及CONFIG_KVM_MMIO有关。可参见内核关于KVM_GET_VCPU_MMAP_SIZE的文档说明:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 4.5 KVM_GET_VCPU_MMAP_SIZE -------------------------- :Capability: basic :Architectures: all :Type: system ioctl :Parameters: none :Returns: size of vcpu mmap area, in bytes The KVM_RUN ioctl (cf.) communicates with userspace via a shared memory region. This ioctl returns the size of that region. See the KVM_RUN documentation for details. Besides the size of the KVM_RUN communication region, other areas of the VCPU file descriptor can be mmap-ed, including: - if KVM_CAP_COALESCED_MMIO is available, a page at KVM_COALESCED_MMIO_PAGE_OFFSET * PAGE_SIZE; for historical reasons, this page is included in the result of KVM_GET_VCPU_MMAP_SIZE. KVM_CAP_COALESCED_MMIO is not documented yet. - if KVM_CAP_DIRTY_LOG_RING is available, a number of pages at KVM_DIRTY_LOG_PAGE_OFFSET * PAGE_SIZE. For more information on KVM_CAP_DIRTY_LOG_RING, see section 8.3. kvmtool得到共享内存的大小后在vcpu-fd上调用mmap，vcpu-fd所关联的file_operations为kvm_vcpu_fops因此会调用到kvm_vcpu_mmap:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 static int kvm_vcpu_mmap(struct file *file, struct vm_area_struct *vma) { struct kvm_vcpu *vcpu = file-\u0026gt;private_data; unsigned long pages = vma_pages(vma); if ((kvm_page_in_dirty_ring(vcpu-\u0026gt;kvm, vma-\u0026gt;vm_pgoff) || kvm_page_in_dirty_ring(vcpu-\u0026gt;kvm, vma-\u0026gt;vm_pgoff + pages - 1)) \u0026amp;\u0026amp; ((vma-\u0026gt;vm_flags \u0026amp; VM_EXEC) || !(vma-\u0026gt;vm_flags \u0026amp; VM_SHARED))) return -EINVAL; // 设置 vma-\u0026gt;vm_ops 为kvm_vcpu_vm_ops vma-\u0026gt;vm_ops = \u0026amp;kvm_vcpu_vm_ops; return 0; } 可以看到，kvmtool调用mmap映射vcpu-fd关联的匿名文件时，仅仅分配了虚拟地址空间，然后设置这段虚拟地址空间的操作为kvm_vcpu_vm_ops，该操作只有一个fault回调函数kvm_vcpu_fault。\n1 2 3 static const struct vm_operations_struct kvm_vcpu_vm_ops = { .fault = kvm_vcpu_fault, }; kvm_vcpu_fault函数会在kvmtool访问共享内存产生缺页异常的时候被调用:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 static vm_fault_t kvm_vcpu_fault(struct vm_fault *vmf) { struct kvm_vcpu *vcpu = vmf-\u0026gt;vma-\u0026gt;vm_file-\u0026gt;private_data; struct page *page; if (vmf-\u0026gt;pgoff == 0) page = virt_to_page(vcpu-\u0026gt;run); #ifdef CONFIG_X86 else if (vmf-\u0026gt;pgoff == KVM_PIO_PAGE_OFFSET) page = virt_to_page(vcpu-\u0026gt;arch.pio_data); #endif #ifdef CONFIG_KVM_MMIO else if (vmf-\u0026gt;pgoff == KVM_COALESCED_MMIO_PAGE_OFFSET) page = virt_to_page(vcpu-\u0026gt;kvm-\u0026gt;coalesced_mmio_ring); #endif else if (kvm_page_in_dirty_ring(vcpu-\u0026gt;kvm, vmf-\u0026gt;pgoff)) page = kvm_dirty_ring_get_page( \u0026amp;vcpu-\u0026gt;dirty_ring, vmf-\u0026gt;pgoff - KVM_DIRTY_LOG_PAGE_OFFSET); else return kvm_arch_vcpu_fault(vcpu, vmf); get_page(page); vmf-\u0026gt;page = page; return 0; } 根据代码:\n访问第一页的时候，实际上会访问到struct kvm_vcpu中的run(struct kvm_run)成员。 访问第二页的时候，实际上会访问到struct kvm_vcpu中的arch(struct kvm_vcpu_arch)成员。 访问第三页的时候，实际上会访问到当前struct kvm中的coalesced_mmio_ring成员。 如果访问的地址超过了指定的长度，则调用kvm_arch_vcpu_fault返回VM_FAULT_SIGBUS:\n1 2 3 4 vm_fault_t kvm_arch_vcpu_fault(struct kvm_vcpu *vcpu, struct vm_fault *vmf) { return VM_FAULT_SIGBUS; } vCPU的运行 在旧版本的Intel SDM中，描述了让一个虚拟机运行起来的步骤:\n在非分页内存中分配一个4KB对齐的vmcs区域，其大小通过IA32_VMX_BASIC MSR得到。对于kvm，这个过程主要是通过vmx_create_vcpu调用alloc_vmcs来完成。 初始化vmcs的版本标识，这个过程在alloc_vmcs_cpu中完成。 使用vmcs的物理地址hpa作为操作数执行vmclear指令，这个过程主要通过loaded_vmcs_clear函数最终调用vmcs_clear来完成。如果操作数是指向current vmcs的指针，执行vmclear指令后，指针会被置为FFFFFFFF_FFFFFFFFH。 使用vmcs的物理地址作为操作数执行vmptrld。这个过程由vmx_cpu_load调用vmcs_load来完成。 执行vmwrite指令设置初始化vmcs，在kvm中这个过程由vmx_vcpu_reset完成。 执行vmlaunch指令，使得当前逻辑cpu处于VMX non-root模式。这个过程由vmx_vcpu_run来完成。 步骤1-5在本文档之前已经做过分析，6就是本小节的重点。同样，vCPU运行需要kvmtool和kvm配合一起才能完成。在kvmtool侧一个vCPU其实对应一个用户态线程，其创建完成后，会进入循环状态，等待条件满足时开始运行虚拟机代码。虚拟机执行敏感指令或收到外部中断时，便会触发VM-Exit进入kvm模块处理；部分VM-Exit甚至会退出到kvmtool中进行处理。如下代码为kvmtool中创建vCPU线程:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 static int kvm_cmd_run_work(struct kvm *kvm) { int i; for (i = 0; i \u0026lt; kvm-\u0026gt;nrcpus; i++) { // 根据kvm-\u0026gt;nrcpus创建vcpu线程 if (pthread_create(\u0026amp;kvm-\u0026gt;cpus[i]-\u0026gt;thread, NULL, kvm_cpu_thread, kvm-\u0026gt;cpus[i]) != 0) die(\u0026#34;unable to create KVM VCPU thread\u0026#34;); } /* Only VCPU #0 is going to exit by itself when shutting down */ if (pthread_join(kvm-\u0026gt;cpus[0]-\u0026gt;thread, NULL) != 0) die(\u0026#34;unable to join with vcpu 0\u0026#34;); return kvm_cpu__exit(kvm); } kvmtool和kvm交互如下图所示:\nkvm_cpu__setup_cpuid:使用KVM_SET_CPUID2调用ioctl设置vCPU对CPUID指令的响应。 kvm_cpu__setup_sregs:使用KVM_SET_SREGS调用ioctl设置vCPU中特殊寄存器(cs,ss,ds,es,fs,gs)的值。 kvm_cpu__setup_regs:使用KVM_SET_REGS调用ioctl设置vCPU中寄存器(rflags,rip,rsp,rbp)的值。 kvm_cpu__setup_fpu:使用KVM_SET_FPU调用ioctl设置vCPU中float point state。 kvm_cpu__setup_msrs:使用KVM_SET_MSRS调用ioctl设置vCPU中的model-specific registers。 kvm_cpu__run:使用KVM_RUN调用ioctl运行vCPU。 函数**kvm_cpu__start**注册虚拟机相关的信号处理函数，设置vCPU的某些状态以及根据vCPU是否running注入NMI，然后调用kvm_cpu__run执行ioctl(vcpu-\u0026gt;vcpu_fd, KVM_RUN, 0)。当vCPU发生VM-Exit并且kvm无法处理此类型退出，就返回到kvmtool中根据cpu-\u0026gt;kvm_run-\u0026gt;exit_reason进行处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 int kvm_cpu__start(struct kvm_cpu *cpu) { sigset_t sigset; sigemptyset(\u0026amp;sigset); sigaddset(\u0026amp;sigset, SIGALRM); pthread_sigmask(SIG_BLOCK, \u0026amp;sigset, NULL); signal(SIGKVMEXIT, kvm_cpu_signal_handler); signal(SIGKVMPAUSE, kvm_cpu_signal_handler); signal(SIGKVMTASK, kvm_cpu_signal_handler); kvm_cpu__reset_vcpu(cpu); if (cpu-\u0026gt;kvm-\u0026gt;cfg.single_step) kvm_cpu__enable_singlestep(cpu); while (cpu-\u0026gt;is_running) { if (cpu-\u0026gt;needs_nmi) { kvm_cpu__arch_nmi(cpu); cpu-\u0026gt;needs_nmi = 0; } if (cpu-\u0026gt;task) kvm_cpu__run_task(cpu); kvm_cpu__run(cpu); switch (cpu-\u0026gt;kvm_run-\u0026gt;exit_reason) { case KVM_EXIT_UNKNOWN: break; case KVM_EXIT_DEBUG: kvm_cpu__show_registers(cpu); kvm_cpu__show_code(cpu); break; case KVM_EXIT_IO: { bool ret; // 模拟IO ret = kvm_cpu__emulate_io(cpu, cpu-\u0026gt;kvm_run-\u0026gt;io.port, (u8 *)cpu-\u0026gt;kvm_run + cpu-\u0026gt;kvm_run-\u0026gt;io.data_offset, cpu-\u0026gt;kvm_run-\u0026gt;io.direction, cpu-\u0026gt;kvm_run-\u0026gt;io.size, cpu-\u0026gt;kvm_run-\u0026gt;io.count); if (!ret) goto panic_kvm; break; } case KVM_EXIT_MMIO: { bool ret; /* * If we had MMIO exit, coalesced ring should be processed * *before* processing the exit itself */ kvm_cpu__handle_coalesced_mmio(cpu); ret = kvm_cpu__emulate_mmio(cpu, cpu-\u0026gt;kvm_run-\u0026gt;mmio.phys_addr, cpu-\u0026gt;kvm_run-\u0026gt;mmio.data, cpu-\u0026gt;kvm_run-\u0026gt;mmio.len, cpu-\u0026gt;kvm_run-\u0026gt;mmio.is_write); if (!ret) goto panic_kvm; break; } case KVM_EXIT_INTR: if (cpu-\u0026gt;is_running) break; goto exit_kvm; case KVM_EXIT_SHUTDOWN: goto exit_kvm; case KVM_EXIT_SYSTEM_EVENT: /* * Print the type of system event and * treat all system events as shutdown request. */ switch (cpu-\u0026gt;kvm_run-\u0026gt;system_event.type) { default: pr_warning(\u0026#34;unknown system event type %d\u0026#34;, cpu-\u0026gt;kvm_run-\u0026gt;system_event.type); /* fall through for now */ case KVM_SYSTEM_EVENT_RESET: /* Fall through for now */ case KVM_SYSTEM_EVENT_SHUTDOWN: /* * Ensure that all VCPUs are torn down, * regardless of which CPU generated the event. */ kvm__reboot(cpu-\u0026gt;kvm); goto exit_kvm; }; break; default: { bool ret; ret = kvm_cpu__handle_exit(cpu); if (!ret) goto panic_kvm; break; } } kvm_cpu__handle_coalesced_mmio(cpu); } exit_kvm: return 0; panic_kvm: return 1; } 执行ioctl(vcpu-\u0026gt;vcpu_fd, KVM_RUN, 0)进入kvm的流程如下:\n1 2 3 4 5 6 7 8 kvm_arch_vcpu_ioctl_run(vcpu);-\u0026gt; vcpu_run(vcpu);-\u0026gt; vcpu_enter_guest(vcpu);-\u0026gt; static_call(kvm_x86_run)(vcpu);-\u0026gt; vmx_vcpu_run(vcpu);-\u0026gt; vmx_vcpu_enter_exit(vcpu, vmx);-\u0026gt; __vmx_vcpu_run(vmx, (unsigned long *)\u0026amp;vcpu-\u0026gt;arch.regs, vmx-\u0026gt;loaded_vmcs-\u0026gt;launched)(arch/x86/kvm/vmx/vmenter.S);-\u0026gt; vmx_vmenter 最终调用__vmx_vcpu_run函数进入vCPU运行的真正入口，其中(unsigned long *)\u0026amp;vcpu-\u0026gt;arch.regs是由kvm保存vCPU的通用寄存器。\nSystem V AMD64 ABI 前六个整型或指针参数依次使用寄存器 rdi, rsi, rdx, rcx, r8, r9。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 /** * __vmx_vcpu_run - Run a vCPU via a transition to VMX guest mode * @vmx:\tstruct vcpu_vmx * (forwarded to vmx_update_host_rsp) * @regs:\tunsigned long * (to guest registers) * @launched:\t%true if the VMCS has been launched * * Returns: *\t0 on VM-Exit, 1 on VM-Fail */ SYM_FUNC_START(__vmx_vcpu_run) push %_ASM_BP mov %_ASM_SP, %_ASM_BP #ifdef CONFIG_X86_64 push %r15 push %r14 push %r13 push %r12 #else push %edi push %esi #endif push %_ASM_BX /* * Save @regs, _ASM_ARG2 may be modified by vmx_update_host_rsp() and * @regs is needed after VM-Exit to save the guest\u0026#39;s register values. */ push %_ASM_ARG2 /* Copy @launched to BL, _ASM_ARG3 is volatile. */ mov %_ASM_ARG3B, %bl /* Adjust RSP to account for the CALL to vmx_vmenter(). */ lea -WORD_SIZE(%_ASM_SP), %_ASM_ARG2 call vmx_update_host_rsp /* Load @regs to RAX. */ mov (%_ASM_SP), %_ASM_AX /* Check if vmlaunch or vmresume is needed */ testb %bl, %bl /* Load guest registers. Don\u0026#39;t clobber flags. */ mov VCPU_RCX(%_ASM_AX), %_ASM_CX mov VCPU_RDX(%_ASM_AX), %_ASM_DX mov VCPU_RBX(%_ASM_AX), %_ASM_BX mov VCPU_RBP(%_ASM_AX), %_ASM_BP mov VCPU_RSI(%_ASM_AX), %_ASM_SI mov VCPU_RDI(%_ASM_AX), %_ASM_DI #ifdef CONFIG_X86_64 mov VCPU_R8 (%_ASM_AX), %r8 mov VCPU_R9 (%_ASM_AX), %r9 mov VCPU_R10(%_ASM_AX), %r10 mov VCPU_R11(%_ASM_AX), %r11 mov VCPU_R12(%_ASM_AX), %r12 mov VCPU_R13(%_ASM_AX), %r13 mov VCPU_R14(%_ASM_AX), %r14 mov VCPU_R15(%_ASM_AX), %r15 #endif /* Load guest RAX. This kills the @regs pointer! */ mov VCPU_RAX(%_ASM_AX), %_ASM_AX /* Enter guest mode */ call vmx_vmenter /* Jump on VM-Fail. */ jbe 2f /* Temporarily save guest\u0026#39;s RAX. */ push %_ASM_AX /* Reload @regs to RAX. */ mov WORD_SIZE(%_ASM_SP), %_ASM_AX /* Save all guest registers, including RAX from the stack */ pop VCPU_RAX(%_ASM_AX) mov %_ASM_CX, VCPU_RCX(%_ASM_AX) mov %_ASM_DX, VCPU_RDX(%_ASM_AX) mov %_ASM_BX, VCPU_RBX(%_ASM_AX) mov %_ASM_BP, VCPU_RBP(%_ASM_AX) mov %_ASM_SI, VCPU_RSI(%_ASM_AX) mov %_ASM_DI, VCPU_RDI(%_ASM_AX) #ifdef CONFIG_X86_64 mov %r8, VCPU_R8 (%_ASM_AX) mov %r9, VCPU_R9 (%_ASM_AX) mov %r10, VCPU_R10(%_ASM_AX) mov %r11, VCPU_R11(%_ASM_AX) mov %r12, VCPU_R12(%_ASM_AX) mov %r13, VCPU_R13(%_ASM_AX) mov %r14, VCPU_R14(%_ASM_AX) mov %r15, VCPU_R15(%_ASM_AX) #endif /* Clear RAX to indicate VM-Exit (as opposed to VM-Fail). */ xor %eax, %eax /* * Clear all general purpose registers except RSP and RAX to prevent * speculative use of the guest\u0026#39;s values, even those that are reloaded * via the stack. In theory, an L1 cache miss when restoring registers * could lead to speculative execution with the guest\u0026#39;s values. * Zeroing XORs are dirt cheap, i.e. the extra paranoia is essentially * free. RSP and RAX are exempt as RSP is restored by hardware during * VM-Exit and RAX is explicitly loaded with 0 or 1 to return VM-Fail. */ 1:\txor %ecx, %ecx xor %edx, %edx xor %ebx, %ebx xor %ebp, %ebp xor %esi, %esi xor %edi, %edi #ifdef CONFIG_X86_64 xor %r8d, %r8d xor %r9d, %r9d xor %r10d, %r10d xor %r11d, %r11d xor %r12d, %r12d xor %r13d, %r13d xor %r14d, %r14d xor %r15d, %r15d #endif /* \u0026#34;POP\u0026#34; @regs. */ add $WORD_SIZE, %_ASM_SP pop %_ASM_BX #ifdef CONFIG_X86_64 pop %r12 pop %r13 pop %r14 pop %r15 #else pop %esi pop %edi #endif pop %_ASM_BP RET /* VM-Fail. Out-of-line to avoid a taken Jcc after VM-Exit. */ 2:\tmov $1, %eax jmp 1b SYM_FUNC_END(__vmx_vcpu_run) 上述汇编代码的功能:\n将host的某些通用寄存器入栈保存。 从vcpu-\u0026gt;arch.regs数组中加载对应的vcpu寄存器值到对应寄存器中。 根据vmx-\u0026gt;loaded_vmcs-\u0026gt;launched的值，决定在VM-Entry时是使用vmlaunch还是vmresume，区别在于是否在同一逻辑cpu上运行。 在执行call vmx_vmenter的时候会将当前host rip(jbe 2f)压栈，在vmx_vmenter中会使得当前逻辑cpu进入VMX Non-Root Operation。\nvmx_vmenter中根据RFLAGS.ZF的值来决定使用vmlaunch还是vmresume:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 /** * vmx_vmenter - VM-Enter the current loaded VMCS * * %RFLAGS.ZF:\t!VMCS.LAUNCHED, i.e. controls VMLAUNCH vs. VMRESUME * * Returns: *\t%RFLAGS.CF is set on VM-Fail Invalid *\t%RFLAGS.ZF is set on VM-Fail Valid *\t%RFLAGS.{CF,ZF} are cleared on VM-Success, i.e. VM-Exit * * Note that VMRESUME/VMLAUNCH fall-through and return directly if * they VM-Fail, whereas a successful VM-Enter + VM-Exit will jump * to vmx_vmexit. */ SYM_FUNC_START_LOCAL(vmx_vmenter) /* EFLAGS.ZF is set if VMCS.LAUNCHED == 0 */ je 2f 1:\tvmresume RET 2:\tvmlaunch RET 3:\tcmpb $0, kvm_rebooting je 4f RET 4:\tud2 _ASM_EXTABLE(1b, 3b) _ASM_EXTABLE(2b, 3b) SYM_FUNC_END(vmx_vmenter) 当逻辑cpu发生VM-Exit也即切换到VMX Root Operation时会加载vmcs host state area中的rip，此时控制流会切到vmx_vmexit，这是因为vmcs中的host rip被设置到此处:\n1 2 3 4 5 6 7 8 9 10 11 12 /* * Set up the vmcs\u0026#39;s constant host-state fields, i.e., host-state fields that * will not change in the lifetime of the guest. * Note that host-state that does change is set elsewhere. E.g., host-state * that is set differently for each CPU is set in vmx_vcpu_load(), not here. */ void vmx_set_constant_host_state(struct vcpu_vmx *vmx) { ...; vmcs_writel(HOST_RIP, (unsigned long)vmx_vmexit); ...; } 如下为vmx_vmexit的实现:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // arch/x86/kvm/vmx/vmenter.S SYM_FUNC_START(vmx_vmexit) #ifdef CONFIG_RETPOLINE ALTERNATIVE \u0026#34;jmp .Lvmexit_skip_rsb\u0026#34;, \u0026#34;\u0026#34;, X86_FEATURE_RETPOLINE /* Preserve guest\u0026#39;s RAX, it\u0026#39;s used to stuff the RSB. */ push %_ASM_AX /* IMPORTANT: Stuff the RSB immediately after VM-Exit, before RET! */ FILL_RETURN_BUFFER %_ASM_AX, RSB_CLEAR_LOOPS, X86_FEATURE_RETPOLINE /* Clear RFLAGS.CF and RFLAGS.ZF to preserve VM-Exit, i.e. !VM-Fail. */ or $1, %_ASM_AX pop %_ASM_AX .Lvmexit_skip_rsb: #endif ret SYM_FUNC_END(vmx_vmexit) 这里要做的就是在VM-Exit后的第一时间填充覆盖RSB，防御对VM Spectre-type攻击。之后执行ret返回到__vmx_vcpu_run中继续执行。由于ret指令会执行pop rip让rip指向调用vmx_vmexit时的后一条指令，其实就是执行jbe 2f。指令jbe 2f根据RFLAGS.{CF,ZF}的值来决定是否跳转。最后__vmx_vcpu_run继续执行保存vCPU寄存器的值，恢复逻辑cpu的状态。\n当vmx_vcpu_enter_exit返回到vmx_vcpu_run后，会调用vmcs_read32读出从current-vmcs中读出VM-Exit的原因:\n1 vmx-\u0026gt;exit_reason.full = vmcs_read32(VM_EXIT_REASON); 接下来vmx_vcpu_run函数将loaded_vmcs设置为true并且检查能否在kvm中快速处理本次VM-Exit:\n1 2 3 vmx-\u0026gt;loaded_vmcs-\u0026gt;launched = 1; ...; return vmx_exit_handlers_fastpath(vcpu); 1 2 3 4 5 6 7 8 9 10 11 static fastpath_t vmx_exit_handlers_fastpath(struct kvm_vcpu *vcpu) { switch (to_vmx(vcpu)-\u0026gt;exit_reason.basic) { case EXIT_REASON_MSR_WRITE: return handle_fastpath_set_msr_irqoff(vcpu); case EXIT_REASON_PREEMPTION_TIMER: return handle_fastpath_preemption_timer(vcpu); default: return EXIT_FASTPATH_NONE; } } 从vmx_vcpu_run返回vcpu_enter_guest后，通过vmx_handle_exit根据vmx-\u0026gt;exit_reason.full调用全局数组kvm_vmx_exit_handlers对应的VM-Exit函数:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 /* * The exit handlers return 1 if the exit was handled fully and guest execution * may resume. Otherwise they set the kvm_run parameter to indicate what needs * to be done to userspace and return 0. */ static int (*kvm_vmx_exit_handlers[])(struct kvm_vcpu *vcpu) = { [EXIT_REASON_EXCEPTION_NMI] = handle_exception_nmi, [EXIT_REASON_EXTERNAL_INTERRUPT] = handle_external_interrupt, [EXIT_REASON_TRIPLE_FAULT] = handle_triple_fault, [EXIT_REASON_NMI_WINDOW]\t= handle_nmi_window, [EXIT_REASON_IO_INSTRUCTION] = handle_io, [EXIT_REASON_CR_ACCESS] = handle_cr, [EXIT_REASON_DR_ACCESS] = handle_dr, [EXIT_REASON_CPUID] = kvm_emulate_cpuid, [EXIT_REASON_MSR_READ] = kvm_emulate_rdmsr, [EXIT_REASON_MSR_WRITE] = kvm_emulate_wrmsr, [EXIT_REASON_INTERRUPT_WINDOW] = handle_interrupt_window, [EXIT_REASON_HLT] = kvm_emulate_halt, [EXIT_REASON_INVD]\t= kvm_emulate_invd, [EXIT_REASON_INVLPG]\t= handle_invlpg, [EXIT_REASON_RDPMC] = kvm_emulate_rdpmc, [EXIT_REASON_VMCALL] = kvm_emulate_hypercall, [EXIT_REASON_VMCLEAR]\t= handle_vmx_instruction, [EXIT_REASON_VMLAUNCH]\t= handle_vmx_instruction, [EXIT_REASON_VMPTRLD]\t= handle_vmx_instruction, [EXIT_REASON_VMPTRST]\t= handle_vmx_instruction, [EXIT_REASON_VMREAD]\t= handle_vmx_instruction, [EXIT_REASON_VMRESUME]\t= handle_vmx_instruction, [EXIT_REASON_VMWRITE]\t= handle_vmx_instruction, [EXIT_REASON_VMOFF]\t= handle_vmx_instruction, [EXIT_REASON_VMON]\t= handle_vmx_instruction, [EXIT_REASON_TPR_BELOW_THRESHOLD] = handle_tpr_below_threshold, [EXIT_REASON_APIC_ACCESS] = handle_apic_access, [EXIT_REASON_APIC_WRITE] = handle_apic_write, [EXIT_REASON_EOI_INDUCED] = handle_apic_eoi_induced, [EXIT_REASON_WBINVD] = kvm_emulate_wbinvd, [EXIT_REASON_XSETBV] = kvm_emulate_xsetbv, [EXIT_REASON_TASK_SWITCH] = handle_task_switch, [EXIT_REASON_MCE_DURING_VMENTRY] = handle_machine_check, [EXIT_REASON_GDTR_IDTR]\t= handle_desc, [EXIT_REASON_LDTR_TR]\t= handle_desc, [EXIT_REASON_EPT_VIOLATION]\t= handle_ept_violation, [EXIT_REASON_EPT_MISCONFIG] = handle_ept_misconfig, [EXIT_REASON_PAUSE_INSTRUCTION] = handle_pause, [EXIT_REASON_MWAIT_INSTRUCTION]\t= kvm_emulate_mwait, [EXIT_REASON_MONITOR_TRAP_FLAG] = handle_monitor_trap, [EXIT_REASON_MONITOR_INSTRUCTION] = kvm_emulate_monitor, [EXIT_REASON_INVEPT] = handle_vmx_instruction, [EXIT_REASON_INVVPID] = handle_vmx_instruction, [EXIT_REASON_RDRAND] = kvm_handle_invalid_op, [EXIT_REASON_RDSEED] = kvm_handle_invalid_op, [EXIT_REASON_PML_FULL]\t= handle_pml_full, [EXIT_REASON_INVPCID] = handle_invpcid, [EXIT_REASON_VMFUNC]\t= handle_vmx_instruction, [EXIT_REASON_PREEMPTION_TIMER]\t= handle_preemption_timer, [EXIT_REASON_ENCLS]\t= handle_encls, [EXIT_REASON_BUS_LOCK] = handle_bus_lock_vmexit, }; 对于上述VM-Exit事件来说，有的kvm能够自己处理，此时由kvm处理后直接返回，准备下一次 VM-Entry；如果kvm无法处理，比如由于IO指令触发的EXIT_REASON_IO_INSTRUCTION，则需要返回到kvmtool中进行处理:\nhandle_io:此函数处理的对应事件是EXIT_REASON_IO_INSTRUCTION，最终会调用到emulator_pio_in_out:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 static int emulator_pio_in_out(struct kvm_vcpu *vcpu, int size, unsigned short port, unsigned int count, bool in) { vcpu-\u0026gt;arch.pio.port = port; vcpu-\u0026gt;arch.pio.in = in; vcpu-\u0026gt;arch.pio.count = count; vcpu-\u0026gt;arch.pio.size = size; if (!kernel_pio(vcpu, vcpu-\u0026gt;arch.pio_data)) return 1; vcpu-\u0026gt;run-\u0026gt;exit_reason = KVM_EXIT_IO; vcpu-\u0026gt;run-\u0026gt;io.direction = in ? KVM_EXIT_IO_IN : KVM_EXIT_IO_OUT; vcpu-\u0026gt;run-\u0026gt;io.size = size; vcpu-\u0026gt;run-\u0026gt;io.data_offset = KVM_PIO_PAGE_OFFSET * PAGE_SIZE; vcpu-\u0026gt;run-\u0026gt;io.count = count; vcpu-\u0026gt;run-\u0026gt;io.port = port; return 0; } 可以看到emulator_pio_in_out函数中会设置vcpu-\u0026gt;run-\u0026gt;exit_reason为KVM_EXIT_IO并且最终返回0，这将导致vcpu_run退出循环并返回到kvmtool中进行处理:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 static int vcpu_run(struct kvm_vcpu *vcpu) { ...; for (;;) { if (kvm_vcpu_running(vcpu)) { r = vcpu_enter_guest(vcpu); } else { r = vcpu_block(kvm, vcpu); } //如果vcpu_enter_guest返回值小于等于0直接跳出循环返回到kvmtool if (r \u0026lt;= 0) break; ...; } //返回到用户态kvmtool中 return r; 此时kvmtool在函数kvm_cpu__start中根据cpu-\u0026gt;kvm_run-\u0026gt;exit_reason进行处理。kvm_cpu__start函数的定义请参见前面的内容。\nvCPU的调度 vCPU在不同的逻辑cpu上运行时会影响虚拟机的性能。这是因为在同一个逻辑cpu上调度vCPU时，只需要执行一次vmlaunch指令，后续每次VM-Entry则只执行vmresume指令；如果vCPU在不同的逻辑cpu之间来回切换，则切换一次需要执行vmclear,vmptrld,vmlaunch三个指令。\n虚拟机的每一个vCPU对应kvmtool中的一个线程，通过宿主机内核调度器进行统一调度管理。若没有将虚拟机的vCPU线程绑定到逻辑cpu上，那么vCPU线程可能在每次运行时被调度到不同的逻辑cpu上。\n如下为将vCPU调度到不同逻辑cpu的基本步骤:\n在源逻辑cpu上执行vmclear指令，将当前逻辑cpu关联的vmcs某些数据复制到vmcs region所在的内存中，并且设置vmcs的launch state为clear。 在目的逻辑cpu以vCPU的vmcs物理地址为操作数执行vmptrld指令。 在目的逻辑cpu上执行vmlaunch指令。 对于kvm来说，首先每个逻辑cpu有一个指向vmcs结构体的指针per_cpu变量current_vmcs:\n1 2 DECLARE_PER_CPU(struct vmcs *, current_vmcs); // arch/x86/kvm/vmx/vmcs.h DEFINE_PER_CPU(struct vmcs *, current_vmcs); // arch/x86/kvm/vmx/vmx.c 每一个vCPU也会分配vmcs结构，这是vmx_create_vcpu调用alloc_loaded_vmcs分配并保存在vmx-\u0026gt;loaded_vmcs-\u0026gt;vmcs成员中。vCPU的调度的本质就是逻辑cpu的current_vmcs在某一时刻指向vCPU的vmcs。\nvcpu_load和vcpu_put是实现vCPU调度的关键。\nvcpu_load vcpu_load函数定义如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 /* * Switches to specified vcpu, until a matching vcpu_put() */ void vcpu_load(struct kvm_vcpu *vcpu) { int cpu = get_cpu(); __this_cpu_write(kvm_running_vcpu, vcpu); preempt_notifier_register(\u0026amp;vcpu-\u0026gt;preempt_notifier); kvm_arch_vcpu_load(vcpu, cpu); put_cpu(); } EXPORT_SYMBOL_GPL(vcpu_load); get_cpu禁止抢占并且返回当前逻辑cpuID，put_cpu开启抢占。 preempt_notifier_register注册抢占回调vcpu-\u0026gt;preempt_notifier，这个通知对象的回调函数在创建vCPU时调用preempt_notifier_init初始化为kvm_preempt_ops。而kvm_preempt_ops.sched_in和kvm_preempt_ops.sched_out在执行kvm_init时分别初始化为kvm_sched_in和kvm_sched_out。当vCPU线程被抢占的时候会调用kvm_sched_out，当vCPU线程抢占了别的线程时会调用kvm_sched_in。 kvm_arch_vcpu_load:最终调用vmx_vcpu_load调度vCPU到指定的逻辑cpu上，具体的逻辑参见kvm_arch_vcpu_load。 kvm_arch_vcpu_load kvm_arch_vcpu_load函数核心部分如下\n1 2 3 4 5 6 void kvm_arch_vcpu_load(struct kvm_vcpu *vcpu, int cpu) { ...; static_call(kvm_x86_vcpu_load)(vcpu, cpu); ...; } 本质就是调用vmx_vcpu_load:\n1 2 3 4 5 6 7 8 9 10 /* * Switches to specified vcpu, until a matching vcpu_put(), but assumes * vcpu mutex is already taken. */ static void vmx_vcpu_load(struct kvm_vcpu *vcpu, int cpu) { struct vcpu_vmx *vmx = to_vmx(vcpu); vmx_vcpu_load_vmcs(vcpu, cpu, NULL); ...; } 最终vcpu调度的实现其实是vmx_vcpu_load_vmcs：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 void vmx_vcpu_load_vmcs(struct kvm_vcpu *vcpu, int cpu, struct loaded_vmcs *buddy) { struct vcpu_vmx *vmx = to_vmx(vcpu); bool already_loaded = vmx-\u0026gt;loaded_vmcs-\u0026gt;cpu == cpu; struct vmcs *prev; if (!already_loaded) { loaded_vmcs_clear(vmx-\u0026gt;loaded_vmcs); local_irq_disable(); /* * Ensure loaded_vmcs-\u0026gt;cpu is read before adding loaded_vmcs to * this cpu\u0026#39;s percpu list, otherwise it may not yet be deleted * from its previous cpu\u0026#39;s percpu list. Pairs with the * smb_wmb() in __loaded_vmcs_clear(). */ smp_rmb(); list_add(\u0026amp;vmx-\u0026gt;loaded_vmcs-\u0026gt;loaded_vmcss_on_cpu_link, \u0026amp;per_cpu(loaded_vmcss_on_cpu, cpu)); local_irq_enable(); } prev = per_cpu(current_vmcs, cpu); if (prev != vmx-\u0026gt;loaded_vmcs-\u0026gt;vmcs) { per_cpu(current_vmcs, cpu) = vmx-\u0026gt;loaded_vmcs-\u0026gt;vmcs; vmcs_load(vmx-\u0026gt;loaded_vmcs-\u0026gt;vmcs); /* * No indirect branch prediction barrier needed when switching * the active VMCS within a guest, e.g. on nested VM-Enter. * The L1 VMM can protect itself with retpolines, IBPB or IBRS. */ if (!buddy || WARN_ON_ONCE(buddy-\u0026gt;vmcs != prev)) indirect_branch_prediction_barrier(); } if (!already_loaded) { void *gdt = get_current_gdt_ro(); /* * Flush all EPTP/VPID contexts, the new pCPU may have stale * TLB entries from its previous association with the vCPU. */ kvm_make_request(KVM_REQ_TLB_FLUSH, vcpu); /* * Linux uses per-cpu TSS and GDT, so set these when switching * processors. See 22.2.4. */ vmcs_writel(HOST_TR_BASE, (unsigned long)\u0026amp;get_cpu_entry_area(cpu)-\u0026gt;tss.x86_tss); vmcs_writel(HOST_GDTR_BASE, (unsigned long)gdt); /* 22.2.4 */ if (IS_ENABLED(CONFIG_IA32_EMULATION) || IS_ENABLED(CONFIG_X86_32)) { /* 22.2.3 */ vmcs_writel(HOST_IA32_SYSENTER_ESP, (unsigned long)(cpu_entry_stack(cpu) + 1)); } vmx-\u0026gt;loaded_vmcs-\u0026gt;cpu = cpu; } } 判断vmx-\u0026gt;loaded_vmcs-\u0026gt;cpu与给定的逻辑cpu是否相等，若不相等:\nloaded_vmcs_clear到loaded_vmcs-\u0026gt;cpu指定的逻辑cpu执行vmclear指令。\n取出当前逻辑cpu的per_cpu变量current_vmcs与vmx-\u0026gt;loaded_vmcs-\u0026gt;vmcs做比较，若相等则调用vmcs_load以vmx-\u0026gt;loaded_vmcs-\u0026gt;vmcs为操作数执行vmptrld指令。\n1 2 3 4 5 6 7 8 9 static inline void vmcs_load(struct vmcs *vmcs) { u64 phys_addr = __pa(vmcs); if (static_branch_unlikely(\u0026amp;enable_evmcs)) return evmcs_load(phys_addr); vmx_asm1(vmptrld, \u0026#34;m\u0026#34;(phys_addr), vmcs, phys_addr); } 设置vmx-\u0026gt;loaded_vmcs-\u0026gt;cpu为当前逻辑cpu，结束vmx_vcpu_load_vmcs并返回上一级调用。\nvcpu_put vcpu_put函数的定义如下:\n1 2 3 4 5 6 7 8 void vcpu_put(struct kvm_vcpu *vcpu) { preempt_disable(); kvm_arch_vcpu_put(vcpu); preempt_notifier_unregister(\u0026amp;vcpu-\u0026gt;preempt_notifier); __this_cpu_write(kvm_running_vcpu, NULL); preempt_enable(); } 通过kvm_arch_vcpu_put最终调用到vmx_vcpu_put:\n1 2 3 4 5 6 static void vmx_vcpu_put(struct kvm_vcpu *vcpu) { vmx_vcpu_pi_put(vcpu); vmx_prepare_switch_to_host(to_vmx(vcpu)); } 可以看到vcpu_put其实就是vcpu_load的逆过程。\nkvm_sched_in 根据之前vCPU创建流程，如果是第一次调用ioctl(KVM_RUN)，宿主机调度器在调度vCPU时使用vcpu_load；如果ioctl(KVM_RUN)不是第一次调用，则通过kvm_sched_in调用kvm_arch_vcpu_load最终调用到vmx_vcpu_load:\n1 2 3 4 5 6 7 8 9 10 11 static void kvm_sched_in(struct preempt_notifier *pn, int cpu) { struct kvm_vcpu *vcpu = preempt_notifier_to_vcpu(pn); WRITE_ONCE(vcpu-\u0026gt;preempted, false); WRITE_ONCE(vcpu-\u0026gt;ready, false); __this_cpu_write(kvm_running_vcpu, vcpu); kvm_arch_sched_in(vcpu, cpu); kvm_arch_vcpu_load(vcpu, cpu); } 当逻辑cpu执行虚拟机代码时，当前vCPU线程是禁止抢占以及被中断打断的，但是中断可以触发VM-Exit，此时逻辑cpu可以调度其他线程。当再次VM-Entry时，宿主机调度器将vCPU线程调度到其他逻辑cpu，此时需要kvm_sched_in来完成这个动作。\nkvm_sched_out kvm_sched_out是kvm_sched_in的逆过程。当vCPU发生VM-Exit时，宿主机调用kvm_sched_out函数接触当前逻辑cpu与vCPU的关联:\n1 2 3 4 5 6 7 8 9 10 11 12 static void kvm_sched_out(struct preempt_notifier *pn, struct task_struct *next) { struct kvm_vcpu *vcpu = preempt_notifier_to_vcpu(pn); if (current-\u0026gt;on_rq) { WRITE_ONCE(vcpu-\u0026gt;preempted, true); WRITE_ONCE(vcpu-\u0026gt;ready, true); } kvm_arch_vcpu_put(vcpu); __this_cpu_write(kvm_running_vcpu, NULL); } kvm_arch_vcpu_put最终调用vmx_vcpu_put。由于vmx_vcpu_put已经在vcpu_put分析过，此处不再详细说明。\nsimple-kvmtool simple-kvmtool是一个简单的类似于kvmtool的用户态工具，参考自https://lwn.net/Articles/658512/。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 #include \u0026lt;asm/kvm.h\u0026gt; #include \u0026lt;err.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;linux/kvm.h\u0026gt; #include \u0026lt;stddef.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/ioctl.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; int main(void) { int kvmfd, vmfd, vcpufd, ret; const uint8_t guest_code[] = { 0xba, 0xf8, 0x03, /* mov $0x3f8, %dx */ 0xb0, \u0026#39;H\u0026#39;, 0xee,\t/* mov $\u0026#39;H\u0026#39; , %al*/ 0xb0, \u0026#39;e\u0026#39;, 0xee,\t/* out %al, (%dx) */ 0xb0, \u0026#39;l\u0026#39;, 0xee, 0xb0, \u0026#39;l\u0026#39;, 0xee, 0xb0, \u0026#39;o\u0026#39;, 0xee, 0xb0, \u0026#39;,\u0026#39;, 0xee, 0xb0, \u0026#39;H\u0026#39;, 0xee, 0xb0, \u0026#39;o\u0026#39;, 0xee, 0xb0, \u0026#39;s\u0026#39;, 0xee, 0xb0, \u0026#39;t\u0026#39;, 0xee, 0xb0, \u0026#39;\\n\u0026#39;, 0xee, 0xf4,\t/* hlt */ }; uint8_t *mem; struct kvm_sregs sregs; size_t mmap_size; struct kvm_run *run; kvmfd = open(\u0026#34;/dev/kvm\u0026#34;, O_RDWR | O_CLOEXEC); if (kvmfd == -1) { err(1, \u0026#34;/dev/kvm\u0026#34;); } /* Make sure we have the stable version of the API */ ret = ioctl(kvmfd, KVM_GET_API_VERSION, 0); if (ret == -1) err(1, \u0026#34;KVM_GET_API_VERSION\u0026#34;);\tif (ret != 12) errx(1, \u0026#34;KVM_GET_API_VERSION %d, expected 12\u0026#34;, ret); vmfd = ioctl(kvmfd, KVM_CREATE_VM, (unsigned long)0); if (vmfd == -1) err(1, \u0026#34;KVM_CREATE_VM\u0026#34;); /* Allocate one aligned page of guest memory to hold the code. */ mem = mmap(NULL, 0x1000, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, -1, 0); if (!mem) { err(1, \u0026#34;allocating guest memory\u0026#34;); } memcpy(mem, guest_code, sizeof(guest_code)); /* Map it to the second page frame (to avoid the real-mode IDT at 0). */ struct kvm_userspace_memory_region guest_region = { .slot = 0, .guest_phys_addr = 0x1000, .memory_size = 0x1000, .userspace_addr = (uint64_t)mem, }; ret = ioctl(vmfd, KVM_SET_USER_MEMORY_REGION, \u0026amp;guest_region); if (ret == -1) err(1, \u0026#34;KVM_SET_USER_MEMORY_REGION\u0026#34;); vcpufd = ioctl(vmfd, KVM_CREATE_VCPU); if (vcpufd == -1) err(1, \u0026#34;KVM_CREATE_VCPU\u0026#34;); /* Map the shared kvm_run structure and following data. */ ret = ioctl(kvmfd, KVM_GET_VCPU_MMAP_SIZE, NULL); if (ret == -1) err(1, \u0026#34;KVM_GET_MMAP_SIZE\u0026#34;); mmap_size = ret; if (mmap_size \u0026lt; sizeof(*run)) errx(1, \u0026#34;KVM_GET_VCPU_MMAP_SIZE unexpectedly small\u0026#34;); run = mmap(NULL, mmap_size, PROT_READ | PROT_WRITE, MAP_SHARED, vcpufd, 0); if (!run) err(1, \u0026#34;mmap vcpu\u0026#34;); /* Initialize CS to point at 0, via a read-modify-write of sregs. */ ret = ioctl(vcpufd, KVM_GET_SREGS, \u0026amp;sregs); if (ret == -1) err(1, \u0026#34;KVM_GET_SREGS\u0026#34;); sregs.cs.base = 0; sregs.cs.selector = 0; ret = ioctl(vcpufd, KVM_SET_SREGS, \u0026amp;sregs); if (ret == -1) err(1, \u0026#34;KVM_SET_SREGS\u0026#34;); /* Initialize registers: instruction pointer for our code, addends, and * initial flags required by x86 architecture. */ struct kvm_regs regs = { .rip = 0x1000, .rax = 2, .rbx = 2, .rflags = 0x2, }; ret = ioctl(vcpufd, KVM_SET_REGS, \u0026amp;regs); if (ret == -1) err(1, \u0026#34;KVM_SET_REGS\u0026#34;); /* Repeatedly run code and handle VM exits. */ while (1) { ret = ioctl(vcpufd, KVM_RUN, NULL); switch (run-\u0026gt;exit_reason) { case KVM_EXIT_HLT: return 0; case KVM_EXIT_IO: if (run-\u0026gt;io.direction == KVM_EXIT_IO_OUT \u0026amp;\u0026amp; run-\u0026gt;io.size == 1 \u0026amp;\u0026amp; run-\u0026gt;io.port == 0x3f8 \u0026amp;\u0026amp; run-\u0026gt;io.count == 1) { putchar(*(((char*)run) + run-\u0026gt;io.data_offset)); } } } return 0; } 执行的效果如下所示:\n参考资料 深入浅出系统虚拟化原理与实践 qemu/kvm源码解析与应用 系统虚拟化原理与实现 深度探索Linux系统虚化原理与实现 https://notes.caijiqhx.top/ucas/virtualization/vmcs/ https://oenhan.com/kvm-src-3-cpu http://liujunming.top/2021/07/22/Introduction-to-Intel-VMCS-Shadowing-technology/ (虚拟化博客) https://eqqie.cn/index.php/archives/1972 (基于Intel VMX的简易虚拟机) https://www.freesion.com/article/9429791169/ Intel® 64 and IA-32 Architectures Software Developer’s Manual Combined Volumes 1, 2A, 2B, 2C, 2D, 3A, 3B, 3C, 3D, and 4.pdf ","date":"2023-09-17T14:45:20+08:00","permalink":"https://liangxianlong.github.io/post/kernel/virtualization/cpu%E8%99%9A%E6%8B%9F%E5%8C%96/","title":"cpu虚拟化"},{"content":"文件对象 对一个目录项打开多次产生多个文件对象，每个文件对象又可以由多个文件描述符索引用。文件对象没有直接的磁盘映射内容，所以也没有表示自己是否为脏的标记。\n文件对象结构体 每一个被操作系统打开的磁盘文件都要在内存中建立一个file结构的文件对象。如下所示为file结构体定义：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 /* * VFS核心对象：文件对象结构体 */ struct file { union { struct llist_node fu_llist; struct rcu_head fu_rcuhead; } f_u; /* f_path: 包含目录项信息和所属文件系统的挂载点信息 * f_path.mnt: 表示该file实例关联的文件所属文件系统的挂载点信息 * f_path.dentry: 该文件的目录项信息，通过dentry可建立file实例与文件inode的联系，进而找到存放在磁盘上的真正的文件数据。 */ struct path f_path; /* f_inode: 指向与该file实例关联的文件inode，一般情况下f_inode = f_path dentry-\u0026gt;d_inode */ struct inode *f_inode; /* cached value */ /* f_op: 文件操作函数指针列表 */ const struct file_operations *f_op; /* * Protects f_ep, f_flags. * Must not be taken from IRQ context. */ spinlock_t f_lock; enum rw_hint f_write_hint; /* f_count: 记录该文件的引用计数 */ atomic_long_t f_count; /* f_flags: 用户态打开文件时所用的flag */ unsigned int f_flags; /* f_mode: 用户态打开文件时所用的mode */ fmode_t f_mode; struct mutex f_pos_lock; /* f_pos: 文件游标，即文件进行读写指针的当前位置 */ loff_t f_pos; /* f_owner: 文件属主的有关信息、同时也包含与信号传递的相关信息 */ struct fown_struct f_owner; /* f_cred: 指向打开该文件实例的进程cred(task_struct-\u0026gt;cred)，保存了打开该文件实例的进程的相关权限 */ const struct cred *f_cred; /* f_ra: 文件预读状态 */ struct file_ra_state f_ra; u64 f_version; #ifdef CONFIG_SECURITY void *f_security; #endif /* needed for tty driver, and maybe others */ void *private_data; #ifdef CONFIG_EPOLL /* Used by fs/eventpoll.c to link all the hooks to this file */ struct hlist_head *f_ep; #endif /* #ifdef CONFIG_EPOLL */ /* f_mapping: 指向与文件相关的inode实例的地址空间映射， * 与文件的page cache有关，页缓存中保存以前访问过的文件数据 */ struct address_space *f_mapping; errseq_t f_wb_err; errseq_t f_sb_err; /* for syncfs */ } __randomize_layout __attribute__((aligned(4))); 文件对象是VFS层为进程打开一个文件时创建的，它调用alloc_empty_file(int flags, const struct cred *cred)函数分配新的file对象，然后根据打开的文件和相关进程填写各个成员。alloc_empty_file函数内部使用kmem_cache_zalloc从filp_cachep高速缓存中获得一个空闲文件对象，然后初始化各个字段。具体流程参见如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 /* Find an unused file structure and return a pointer to it. * Returns an error pointer if some error happend e.g. we over file * structures limit, run out of memory or operation is not permitted. * * Be very careful using this. You are responsible for * getting write access to any mount that you might assign * to this filp, if it is opened for write. If this is not * done, you will imbalance int the mount\u0026#39;s writer count * and a warning at __fput() time. */ struct file *alloc_empty_file(int flags, const struct cred *cred) |——\u0026gt;__alloc_file(flags, cred); |——\u0026gt;kmem_cache_zalloc(filp_cachep, GFP_KERNEL); 文件对象的内存管理使用一个filp_cache的slab高速缓存(在/proc/slabinfo中显示为filp)。\n1 2 /* SLAB cache for file structures */ static struct kmem_cache *filp_cachep __read_mostly; 系统中允许的最大文件对象数目由files_stat_struct变量中的max_files字段中做出限制，如下代码所示。\n1 2 3 4 /* sysctl tunables... */ struct files_stat_struct files_stat = { .max_files = NR_FILE }; 上述限制可以通过/proc/sys/fs/file-max进行修改，超级用户不受此限制。\n文件操作函数 每个文件系统都有自己的函数操作集合，因此内核打开一个文件时，将这些操作函数指针存放在file-\u0026gt;f_op(struct file_operations)成员中，该结构体及其函数如下所示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 struct file_operations { /* owner: 当文件系统以模块的形式插入系统时使用该成员， * 此时该成员指向内存中表示该模块的数据结构 */ struct module *owner; /* llseek: 用于更新偏移量指针(file-\u0026gt;f_ops) * 将新位置的偏移量作为返回值，由系统调用lseek调用 */ loff_t (*llseek) (struct file *, loff_t, int); /* read: 同步的读给定文件的数据 */ ssize_t (*read) (struct file *, char __user *, size_t, loff_t *); /* write: 同步的写数据到给定文件 */ ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *); ssize_t (*read_iter) (struct kiocb *, struct iov_iter *); ssize_t (*write_iter) (struct kiocb *, struct iov_iter *); int (*iopoll)(struct kiocb *kiocb, bool spin); int (*iterate) (struct file *, struct dir_context *); int (*iterate_shared) (struct file *, struct dir_context *); /* poll: 用于poll和select系统调用，实现同步的I/O多路复用 */ __poll_t (*poll) (struct file *, struct poll_table_struct *); /* unlocked_ioctl：用来给设备文件发送命令参数对 * 相较于ioctl，该函数不需要BKL */ long (*unlocked_ioctl) (struct file *, unsigned int, unsigned long); long (*compat_ioctl) (struct file *, unsigned int, unsigned long); /* mmap：用于指定的文件映射到指定的虚拟地址空间上 * 包括裸设备内存映射到虚拟地址空间 */ int (*mmap) (struct file *, struct vm_area_struct *); unsigned long mmap_supported_flags; /* open：创建一个新的文件对象，并将它和相应的索引节点对象关联 */ int (*open) (struct inode *, struct file *); int (*flush) (struct file *, fl_owner_t id); int (*release) (struct inode *, struct file *); /* fsync：将给定文件的所有被缓存数据写回磁盘 */ int (*fsync) (struct file *, loff_t, loff_t, int datasync); int (*fasync) (int, struct file *, int); /* lock：给指定文件上锁，对文件的并发访问进行互斥保护 */ int (*lock) (struct file *, int, struct file_lock *); ssize_t (*sendpage) (struct file *, struct page *, int, size_t, loff_t *, int); /* get_unmapped_area：获取未使用的虚拟地址空间 */ unsigned long (*get_unmapped_area)(struct file *, unsigned long, unsigned long, unsigned long, unsigned long); int (*check_flags)(int); int (*flock) (struct file *, int, struct file_lock *); /* splice_write * splice_read * 用于从管道向文件传输数据或者从文件向管道写数据 * 上述两个函数通过去除在内核空间和用户空间之间的内存复制开销来提高性能 */ ssize_t (*splice_write)(struct pipe_inode_info *, struct file *, loff_t *, size_t, unsigned int); ssize_t (*splice_read)(struct file *, loff_t *, struct pipe_inode_info *, size_t, unsigned int); int (*setlease)(struct file *, long, struct file_lock **, void **); long (*fallocate)(struct file *file, int mode, loff_t offset, loff_t len); void (*show_fdinfo)(struct seq_file *m, struct file *f); #ifndef CONFIG_MMU unsigned (*mmap_capabilities)(struct file *); #endif ssize_t (*copy_file_range)(struct file *, loff_t, struct file *, loff_t, size_t, unsigned int); loff_t (*remap_file_range)(struct file *file_in, loff_t pos_in, struct file *file_out, loff_t pos_out, loff_t len, unsigned int remap_flags); int (*fadvise)(struct file *, loff_t, loff_t, int); } __randomize_layout; 目录项对象 目录项的作用可以概括为以下两点：\ndentry目录项对象将按树状组织的文件路径名和文件建立联系； file文件对象通过dentry目录项对象可以进一步找到inode对象； 在Linux系统中，dentry组成的树状关系最顶层的目录项对象对应于系统根目录/，中间的目录项形成各级子目录，树的叶子节点关联到普通文件或者特殊文件。此外目录项对象没有对应的磁盘数据结构，所以目录项对象没有是否被修改的标记。\n目录项对象结构体 VFS目录项结构体的定义如下所示。目录项dentry记录文件名与inode的关联，主要涉及目录项对象成员d_name和d_inode。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 /* * VFS核心对象：目录项对象结构体 */ struct dentry { /* RCU lookup touched fields */ /* d_flags: * 1. d_flags=DCACHE_DISCONNECTED表示当前dentry没有链接到超级块的dentry树 * 2. d_flags=DCACHE_MOUNTED表示当前dentry是一个文件系统的挂载点 * 3. d_flags=DCACHE_SYMLINK_TYPE表示该dentry为一个符号链接 */ unsigned int d_flags; /* protected by d_lock */ seqcount_spinlock_t d_seq; /* per dentry seqlock */ /* * d_hash: 系统中所有的dentry实例都挂接在全局变量dentry_hashtable[]散列数组上， * 每个数组元素都是一个链表头(管理相同散列值的dentry)，其中dentry结构中的d_hash用作链表节点， * dentry的hash值由d_hash()函数完成。 */ struct hlist_bl_node d_hash; /* lookup hash list */ /* * d_parent: 指向当前dentry的父dentry实例，同时当前dentry实例则挂接在父dentry实例的d_subdirs * 链上，d_child作为子dentry链表节点。 */ struct dentry *d_parent; /* parent directory */ /* * d_name: 文件名较长时，使用此变量保存 */ struct qstr d_name; /* * d_inode: 指向与该dentry实例关联的文件inode */ struct inode *d_inode; /* Where the name belongs to - NULL is * negative */ unsigned char d_iname[DNAME_INLINE_LEN]; /* small names */ /* Ref lookup also touches following */ struct lockref d_lockref; /* per-dentry lock and refcount */ /* * d_op: 指向当前dentry函数指针表 */ const struct dentry_operations *d_op; /* * d_sb: 指向与该dentry实例所属的超级块 */ struct super_block *d_sb; /* The root of the dentry tree */ unsigned long d_time; /* used by d_revalidate */ void *d_fsdata; /* fs-specific data */ union { struct list_head d_lru; /* LRU list */ wait_queue_head_t *d_wait; /* in-lookup ones only */ }; /* * d_child: 子dentry链表节点，链入d_subdirs */ struct list_head d_child; /* child of parent list */ /* * d_subdirs: 当前dentry所有子dentry链表头 */ struct list_head d_subdirs; /* our children */ /* * d_alias and d_rcu can share memory */ union { /* * d_alias: 作为struct inode-\u0026gt;i_dentry链表的节点 * inode-\u0026gt;i_dentry作为链表表头(在硬链接的情况下两个或多个dentry会关联到通一个inode实例) * 当一个目录项正被引用时，才挂接到i_dentry指向的链表上 */ struct hlist_node d_alias; /* inode alias list */ struct hlist_bl_node d_in_lookup_hash; /* only for in-lookup ones */ /* d_rcu：作为super_block-\u0026gt;s_dentry链表上的节点，保存暂不使用的目录项 */ struct rcu_head d_rcu; } d_u; } __randomize_layout; 关于目录项结构体的成员说明已经参见如上代码。\n目录项层次结构 下图1展示了由dentry对象所表示的目录项层次结构。\n通过图1可知如下事实：\n(1) 父目录项通过d_subdirs指出所有的在用子目录项； (2) 属于同一个父目录项的子目录项之间用d_child形成链表，链表头是父目录项的d_subdirs成员变量； (3) 所有的子目录项通过其d_parent成员变量指向父目录项； (4) 目录项通过d_inode成员变量指向索引节点，反过来索引节点使用i_dentry作为所有指向本索引节点的目录项所构成的链表的表头，目录项中的d_alias作为表中的节点； (5) 目录项作为安装节点，其将跨越两个设备/分区从而起到连接作用； (6) 分属不同的设备/分区，使用不同的超级块来管理；如图1中灰色文件系统中的目录项d_sb成员指向super_block1，挂载在黑色目录项上的文件系统的目录项d_sb成员指向super_block2； 目录项缓存及hash散列表 Linux内核使用dentry_cache缓存用过的目录项，从而加快目录的查找。dentry_cache定义如下。在/proc/slabinfo中显示为dentry。\n1 static struct kmem_cache *dentry_cache __read_mostly; 目录项对象可以处于以下4个状态之一：\n空闲状态(Free)：处于该状态的目录项不包含有效信息，只是由slab分配了空间，未被VFS使用； 未使用状态(Unused)：目录项对象没有使用者，但是其d_inode字段仍然指向关联的索引节点。可在内存紧张时被回收； 在使用状态(In Use)：该状态下的目录项对象正在被内核使用，包含有效信息。该对象的引用计数d_count为正值，d_inode字段指向对应的有效索引节点，不能被丢弃。 无效状态：该状态下的目录项对象原来所关联的索引节点已不复存在，原因可能是相应的磁盘索引节点已被删除或者目录项对象是通过解析一个不存在的文件的路径名创建。该状态下的目录项d_inode字段为NULL，但是其仍在目录项高速缓存中。 目录项挂接在4个不同的表中，分别是用于快速查找的hash链、属于同一inode的别名链、暂不使用的链、同一父目录的子目录链。\n快速查找的hash链：dentry_hashtable全局变量管理目录项的散列表，相同散列值的目录项使用d_hash链接起来，参见图2。根据hash表可以快速查找dentry，否则每次都从树状组织结构的根节点开始逐查找； 正在使用的目录项通过dentry-\u0026gt;d_alias挂入对应文件inode的i_dentry链表上，见图1； 暂未使用和无效状态的目录项挂接到所属分区的超级块super_block-\u0026gt;s_dentry_lru链表上，由对应目录项的d_lru字段作为链表的节点元素，当slab需要回收目录项时，就从该LRU链表上找。参见图2； 属于同一个父目录下的目录项以d_child字段作为节点元素挂接到父目录项的d_subdirs链表上，见图1； 目录项高速缓存在一定程度上提供了对索引节点的缓存，也就是icache。因为目录项高速缓存会让相关索引节点的引用计数为正，这样会导致对应的索引节点也驻留在内存中。\n目录项操作函数 与目录项有关的函数由目录项的d_op字段描述。其声明如下代码所示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 struct dentry_operations { /* * d_revalidate：判断目录项缓存是否有效，该函数对网络文件系统有较大作用。 */ int (*d_revalidate)(struct dentry *, unsigned int); /* * d_weak_revalidate：弱化版本的d_revalidate */ int (*d_weak_revalidate)(struct dentry *, unsigned int); /* * d_hash：为目录项对象生成散列值。 */ int (*d_hash)(const struct dentry *, struct qstr *); /* * d_compare：比较两个文件名。 */ int (*d_compare)(const struct dentry *, unsigned int, const char *, const struct qstr *); /* * d_delete：当目录项引用计数为0时，调用此函数。若此函数返回1表示会删除对应的目录项； * 返回0表示要缓存此目录项。 */ int (*d_delete)(const struct dentry *); /* * d_init：用于在分配目录项时就将其初始化。 */ int (*d_init)(struct dentry *); /* * d_release：用于释放目录项对象。 */ void (*d_release)(struct dentry *); void (*d_prune)(struct dentry *); /* * d_iput：alled when a dentry loses its inode. */ void (*d_iput)(struct dentry *, struct inode *); /* * d_dname：产生目录项名称，通常用于伪文件系统。 */ char *(*d_dname)(struct dentry *, char *, int); /* * d_automount：当dentry实例设置了DCACHE_NEED_AUTOMOUNT标记， * 调用此函数产生vfsmount结构体返回给调用者，调用者可挂载文件系统到此目录项。 */ struct vfsmount *(*d_automount)(struct path *); /* * d_manage：只有设置了DCACHE_MANAGE_TRANSIT标记的dentry实例才有效， * 用于向dentry实例传递信息，正常返回0，不允许返回负的错误码。 */ int (*d_manage)(const struct path *, bool); /* * d_real: 用于返回被overlay等联合文件系统隐藏的目录项，详细说明可参考内核文档 */ struct dentry *(*d_real)(struct dentry *, const struct inode *); } ____cacheline_aligned; 虽然目录项用于建立树状组织关系，但是目录项操作函数却不涉及目录树的查找操作，而是涉及目录项自身的检验、撤销、比较等操作。目录树的遍历查找是在文件打开过程中实施的\n索引节点对象 索引节点包括具体文件系统的索引节点和VFS内存中的通用索引节点两种形式。 索引节点对象包含了内核在操作文件或目录时需要的大量信息，这些信息往往称为文件的元数据(Meta Data)，对于Unix风格的文件系统来说，这些元数据可以从磁盘索引节点直接读入。有些文件系统，如FAT和ReiserFS没有使用索引节点，这些文件系统没有将文件数据和文件元数据分开存放。VFS层面的索引节点必须在内存创建(仅当文件被访问时才会创建)；对某一个具体的文件，索引节点是唯一的，且随着文件的生命周期同步的产生或者撤销。\n索引节点对象结构体 VFS层索引节点对象由结构体struct inode表示，如下为其代码定义。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 /* * Keep mostly read-only and often accessed (especially for * the RCU path lookup and \u0026#39;stat\u0026#39; data) fields at the beginning * of the \u0026#39;struct inode\u0026#39; */ /* * VFS核心对象：inode对象结构体 */ struct inode { /* i_mode: 文件访问类型与权限 * bit15-bit12: 表示文件类型 * bit11-bit9: 用户ID信息 * bit8-bit0: 表示文件访问权限 */ umode_t i_mode; /* i_opflags: 进程打开文件的标记 */ unsigned short i_opflags; /* i_uid: 文件拥有者的id */ kuid_t i_uid; /* i_gid: 文件拥有者的组id */ kgid_t i_gid; unsigned int i_flags; #ifdef CONFIG_FS_POSIX_ACL struct posix_acl *i_acl; struct posix_acl *i_default_acl; #endif /* inode_operations: 索引节点的操作函数列表 */ const struct inode_operations *i_op; /* i_sb: 该索引节点对应的超级块对象 */ struct super_block *i_sb; /* i_mapping: 指向address_space对象(通常指向i_data) */ struct address_space *i_mapping; #ifdef CONFIG_SECURITY void *i_security; #endif /* Stat data, not accessed from path walking */ /* i_ino: inode编号，分区内编号唯一 */ unsigned long i_ino; /* * Filesystems may only read i_nlink directly. They shall use the * following functions for modification: * * (set|clear|inc|drop)_nlink * inode_(inc|dec)_link_count */ union { /* i_nlink: 硬链接数(文件系统自身目录项的引用计数) */ const unsigned int i_nlink; unsigned int __i_nlink; }; /* i_rdev: (设备文件)实际设备标识符 */ dev_t i_rdev; /* i_size: 以字节为单位的文件大小 */ loff_t i_size; /* i_atime: 上次访问文件的时间 */ struct timespec64 i_atime; /* i_mtime: 上次写文件的时间 */ struct timespec64 i_mtime; /* i_ctime: 上次修改索引节点的时间 */ struct timespec64 i_ctime; spinlock_t i_lock; /* i_blocks, i_bytes, maybe i_size */ /* i_bytes: 文件中最后一个块的有效字节数 */ unsigned short i_bytes; /* i_blkbits: 每个块所占位数 */ u8 i_blkbits; u8 i_write_hint; /* i_blocks: 文件的块数 */ blkcnt_t i_blocks; #ifdef __NEED_I_SIZE_ORDERED seqcount_t i_size_seqcount; #endif /* Misc */ /* i_state: 索引节点的状态标志 * i_state = I_DIRTY_SYNC | I_DIRTY_DATASYNC | I_DIRTY_PAGES，则该索引节点是脏的，需要回写索引节点到磁盘上 * i_state = I_LOCK，这个索引节点正处于I/O传送中 * i_state = I_CLEAR，索引节点对象内容已经被清空 * i_state = I_FREEING，索引节点正在被释放 * i_state = I_NEW，该索引节点刚刚分配 */ unsigned long i_state; struct rw_semaphore i_rwsem; /* dirtied_when: 保存文件第一次被修改的时间，主要用于回写操作 */ unsigned long dirtied_when; /* jiffies of first dirtying */ unsigned long dirtied_time_when; /* i_hash：所有的inode通过全局变量inode_hashtable散列，i_hash作为其中链表头 */ struct hlist_node i_hash; struct list_head i_io_list; /* backing dev IO list */ #ifdef CONFIG_CGROUP_WRITEBACK struct bdi_writeback *i_wb; /* the associated cgroup wb */ /* foreign inode detection, see wbc_detach_inode() */ int i_wb_frn_winner; u16 i_wb_frn_avg_time; u16 i_wb_frn_history; #endif /* i_lru: 作为超级块LRU链表中的节点，表头为sb.s_inode_lru，该表管理未被使用且不为脏的inode */ struct list_head i_lru; /* inode LRU list */ /* i_sb_list：作为超级块中inode链表中的节点，表头为sb.s_inodes，该表管理着对应超级快的所有inode */ struct list_head i_sb_list; /* i_wb_list：inode实例作为超级块s_inodes_wb链表中的节点，该表管理该超级块全部待回写的inode */ struct list_head i_wb_list; /* backing dev writeback list */ union { /* i_dentry: 索引节点目录项对象链表的头指针 */ struct hlist_head i_dentry; struct rcu_head i_rcu; }; atomic64_t i_version; atomic64_t i_sequence; /* see futex */ /* i_count: 索引节点的引用计数 */ atomic_t i_count; atomic_t i_dio_count; atomic_t i_writecount; #if defined(CONFIG_IMA) || defined(CONFIG_FILE_LOCKING) atomic_t i_readcount; /* struct files open RO */ #endif union { /* i_fop: 默认的文件操作 */ const struct file_operations *i_fop; /* former -\u0026gt;i_op-\u0026gt;default_file_ops */ void (*free_inode)(struct inode *); }; struct file_lock_context *i_flctx; /* i_data: 文件的address_space对象 */ struct address_space i_data; /* i_devices: 用于链接同一种类型的设备文件的所有inode实例 */ struct list_head i_devices; union { /* i_pipe: 如果文件是管道则使用i_pipe成员变量 */ struct pipe_inode_info *i_pipe; /* i_cdev: 如果文件是字符设备则使用i_cdev成员变量 */ struct cdev *i_cdev; char *i_link; unsigned i_dir_seq; }; __u32 i_generation; #ifdef CONFIG_FSNOTIFY __u32 i_fsnotify_mask; /* all events this inode cares about */ struct fsnotify_mark_connector __rcu *i_fsnotify_marks; #endif #ifdef CONFIG_FS_ENCRYPTION struct fscrypt_info *i_crypt_info; #endif #ifdef CONFIG_FS_VERITY struct fsverity_info *i_verity_info; #endif /* i_private：指向具体文件系统私有数据 */ void *i_private; /* fs or device private pointer */ } __randomize_layout; 索引节点的组织 每个inode实例都关联了几个链表，用于从不同方向来管理系统中的inode实例。\n所属超级块双向链表：该链表管理本分区上的所有inode节点；链表表头为super_block数据结构中的s_inodes成员，inode实例中的成员i_sb_list作为链表节点元素。\n索引节点的hash表：inode节点对象存放在inode_hashtable全局散列表中，用于提高索引节点的检索速度；它利用索引节点号和所在文件系统的超级块对象地址进行散列。inode_hashtable定义如下：\n1 static struct hlist_head *inode_hashtable __read_mostly; 脏inode链表：该链表维护了本分区下待回写的全部脏inode，链表头为super_block数据结构中的s_inodes_wb成员，inode成员i_wb_list作为链表中的节点元素。\n空闲inode链表：该链表维护了未被使用且不为脏的inode，链表表头为super_block数据结构的中的s_inode_lru成员，inode成员i_lru作为链表的节点元素。\n上述所描述的inode节点的组织关系如下图3所示。\ninode不再使用时，不是立刻删除，而是跟随目录项dentry缓存而继续存在。直到所有指向本inode的dentry被删除时，inode的缓存才被删除。需要注意的是，此处所说的inode和dentry都是VFS层对象。\n索引节点操作函数 inode数据结构中的i_op成员，保存了该inode的函数指针。i_op的定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 struct inode_operations { /* * lookup：在给定的目录中(此处给的inode)，根据提供的dentry文件名，查找inode. */ struct dentry * (*lookup) (struct inode *,struct dentry *, unsigned int); /* * get_link: 用于检索符号链接的目标路径. */ const char * (*get_link) (struct dentry *, struct inode *, struct delayed_call *); /* * permission: 检查给定的inode所代表的文件是否允许特定的访问模式. */ int (*permission) (struct user_namespace *, struct inode *, int); struct posix_acl * (*get_acl)(struct inode *, int); /* * readlink: 由系统调用readlink()调用，拷贝数据到特定的buffer中. * 数据来自dentry，拷贝大小最大可达buflen字节.读取的是符号链接指向的目标文件或者目录. */ int (*readlink) (struct dentry *, char __user *,int); /* * create: 由系统调用create()和open()来调用此函数，从而为dentry对象创建一个新的索引节点。 * 在创建时使用mode指定初始模式 */ int (*create) (struct user_namespace *, struct inode *,struct dentry *, umode_t, bool); /* * link: 由系统调用link创建一个新的硬链接，硬链接名称由dentry指定，链接到dir目录中old_dentry代表的文件 */ int (*link) (struct dentry *,struct inode *,struct dentry *); /* * unlink：由系统调用unlink从一个目录中删除目录项对象所指定文件的硬链接， * 如果是最后一个并且没有其他进程在使用此文件，那么会把文件也删除 */ int (*unlink) (struct inode *,struct dentry *); /* * symlink: 由系统调用symlink()调用，创建符号链接。 * 该符号链接的名称由symname指定，链接对象是dir目录中的dentry目录项 */ int (*symlink) (struct user_namespace *, struct inode *,struct dentry *, const char *); /* * mkdir: 由系统调用mkdir调用，创建一个新的子目录 */ int (*mkdir) (struct user_namespace *, struct inode *,struct dentry *, umode_t); /* * rmdir: 从一个目录删除子目录，子目录名称包含在目录项对象中。系统调用rmdir调用。 */ int (*rmdir) (struct inode *,struct dentry *); /* * mknod: 在某个目录中为与目录项对象相关的特定文件(设备、有名管道、socket)创建一个新的磁盘索引节点。 * 由系统调用mknod调用。 */ int (*mknod) (struct user_namespace *, struct inode *,struct dentry *, umode_t,dev_t); /* * rename: 将old_dir目录下由old_entry标识的文件移到new_dir目录项。 * 新文件名包含在new_dentry指向的目录项对象中。 */ int (*rename) (struct user_namespace *, struct inode *, struct dentry *, struct inode *, struct dentry *, unsigned int); /* * setattr: 被系统调用chmod和相关的sysemcall调用，用于设置文件属性. */ int (*setattr) (struct user_namespace *, struct dentry *, struct iattr *); /* * getattr: 被系统调用stat和相关的sysemcall调用，用于获取文件属性. */ int (*getattr) (struct user_namespace *, const struct path *, struct kstat *, u32, unsigned int); ssize_t (*listxattr) (struct dentry *, char *, size_t); int (*fiemap)(struct inode *, struct fiemap_extent_info *, u64 start, u64 len); int (*update_time)(struct inode *, struct timespec64 *, int); int (*atomic_open)(struct inode *, struct dentry *, struct file *, unsigned open_flag, umode_t create_mode); int (*tmpfile) (struct user_namespace *, struct inode *, struct dentry *, umode_t); int (*set_acl)(struct user_namespace *, struct inode *, struct posix_acl *, int); int (*fileattr_set)(struct user_namespace *mnt_userns, struct dentry *dentry, struct fileattr *fa); int (*fileattr_get)(struct dentry *dentry, struct fileattr *fa); } ____cacheline_aligned; 对于struct inode_operations由具体文件系统实现，因此不同文件系统的索引节点其操作函数的具体实现是不同的。此外，不同的文件系统根据自身属性全量实现或者部分实现。\n超级块对象 超级块对象是对一个磁盘分区(一个磁盘可以划分为多个分区)最顶层的描述，这些描述和控制信息称为文件系统的元数据。VFS超级块指的是通用的、内存形态的；而具体的文件系统的超级块则是特定的、盘上的。\n超级块对象结构体 VFS的通用内存形态超级块对象由struct super_block表示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 struct super_block { /* s_list: 系统中所有的超级块形成一个双向循环链表，s_list用作链表节点. 链表头定义为static LIST_HEAD(super_blocks) */ struct list_head s_list; /* Keep this first */ /* s_dev: 包含该具体文件系统的块设备标识符。例如，对于 /dev/hda1，其设备标识符为 0x301 */ dev_t s_dev; /* search index; _not_ kdev_t */ /* 以位为单位的块大小 */ unsigned char s_blocksize_bits; /* 以字节为单位的块大小 */ unsigned long s_blocksize; /* s_maxbytes: 该文件系统可以处理的最大文件长度，不同的文件系统有不同的设置 */ loff_t s_maxbytes; /* Max file size */ /* s_type: 文件系统类型 */ struct file_system_type *s_type; /* s_op: 超级块操作方法函数集 */ const struct super_operations *s_op; /* dq_op: 磁盘限额处理方法 */ const struct dquot_operations *dq_op; /* s_qcop: 磁盘限额处理方法 */ const struct quotactl_ops *s_qcop; /* s_export_op: 主要用于nfsd和文件系统交互用 */ const struct export_operations *s_export_op; /* s_flags: 取值定义在/include/uapi/linux/fs.h头文件内，表示整个文件系统的属性 */ unsigned long s_flags; unsigned long s_iflags; /* internal SB_I_* flags */ unsigned long s_magic; /* s_root: 指向全局根目录(/)的dentry实例 */ struct dentry *s_root; /* s_umount: 卸载此文件系统所使用的信号量 */ struct rw_semaphore s_umount; /* s_count: 引用计数 */ int s_count; atomic_t s_active; #ifdef CONFIG_SECURITY void *s_security; #endif const struct xattr_handler **s_xattr; #ifdef CONFIG_FS_ENCRYPTION const struct fscrypt_operations *s_cop; struct key *s_master_keys; /* master crypto keys in use */ #endif #ifdef CONFIG_FS_VERITY const struct fsverity_operations *s_vop; #endif #ifdef CONFIG_UNICODE struct unicode_map *s_encoding; __u16 s_encoding_flags; #endif struct hlist_bl_head s_roots; /* alternate root dentries for NFS */ struct list_head s_mounts; /* list of mounts; _not_ for fs use */ struct block_device *s_bdev; struct backing_dev_info *s_bdi; struct mtd_info *s_mtd; /* s_instances: 同一类型的多个文件系统可挂载到多个不同目录下形成多个文件系统影像 * 这些文件系统的超级块都挂接在相应的file_system_type结构中fs_supers成员为表头 * 的链表中，s_instances为链表节点 */ struct hlist_node s_instances; unsigned int s_quota_types; /* Bitmask of supported quota types */ struct quota_info s_dquot; /* Diskquota specific options */ struct sb_writers s_writers; /* * Keep s_fs_info, s_time_gran, s_fsnotify_mask, and * s_fsnotify_marks together for cache efficiency. They are frequently * accessed and rarely modified. */ void *s_fs_info; /* Filesystem private info */ /* Granularity of c/m/atime in ns (cannot be worse than a second) */ u32 s_time_gran; /* Time limits for c/m/atime in seconds */ time64_t s_time_min; time64_t s_time_max; #ifdef CONFIG_FSNOTIFY __u32 s_fsnotify_mask; struct fsnotify_mark_connector __rcu *s_fsnotify_marks; #endif char s_id[32]; /* Informational name */ uuid_t s_uuid; /* UUID */ unsigned int s_max_links; fmode_t s_mode; /* * The next field is for VFS *only*. No filesystems have any business * even looking at it. You had been warned. */ struct mutex s_vfs_rename_mutex; /* Kludge */ /* * Filesystem subtype. If non-empty the filesystem type field * in /proc/mounts will be \u0026#34;type.subtype\u0026#34; */ const char *s_subtype; const struct dentry_operations *s_d_op; /* default d_op for dentries */ /* * Saved pool identifier for cleancache (-1 means none) */ int cleancache_poolid; /* s_shrink: slab缓存收缩器，用于页面回收机制 */ struct shrinker s_shrink; /* per-sb shrinker handle */ /* Number of inodes with nlink == 0 but still referenced */ atomic_long_t s_remove_count; /* Pending fsnotify inode refs */ atomic_long_t s_fsnotify_inode_refs; /* Being remounted read-only */ int s_readonly_remount; /* per-sb errseq_t for reporting writeback errors via syncfs */ errseq_t s_wb_err; /* AIO completions deferred from interrupt context */ struct workqueue_struct *s_dio_done_wq; struct hlist_head s_pins; /* * Owning user namespace and default context in which to * interpret filesystem uids, gids, quotas, device nodes, * xattrs and security labels. */ struct user_namespace *s_user_ns; /* * The list_lru structure is essentially just a pointer to a table * of per-node lru lists, each of which has its own spinlock. * There is no need to put them into separate cachelines. */ /* s_dentry_lru: 本分区上的目录项lru队列 */ struct list_lru s_dentry_lru; /* s_inode_lru: 本分区上的索引节点lru */ struct list_lru s_inode_lru; struct rcu_head rcu; struct work_struct destroy_work; struct mutex s_sync_lock; /* sync serialisation lock */ /* * Indicates how deep in a filesystem stack this SB is */ int s_stack_depth; /* s_inode_list_lock protects s_inodes */ spinlock_t s_inode_list_lock ____cacheline_aligned_in_smp; /* s_inodes: s_inodes是一个链表头，该链表保存了本分区上所有的在用的inode */ struct list_head s_inodes; /* all inodes */ spinlock_t s_inode_wblist_lock; /* s_inodes_wb: s_inodes_wb是一个链表表头，该链表上保存了本分区待回写的脏inode */ struct list_head s_inodes_wb; /* writeback inodes */ } __randomize_layout; 在超级块对象结构体的字段中，最重要的是s_type和超级块操作函数集合s_op。\n超级块对象操作函数 各种文件系统都由super_operations来描述其操作函数，但是具体的函数指针将指向不同的代码，这些函数主要用于三个用途：\ninode操作；\nsuper_block操作；\n配额、统计等操作；\n如下所示为struct super_operations。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 struct super_operations { /* alloc_inode: 分配新的inode，该inode与本超级块对象关联 */ struct inode *(*alloc_inode)(struct super_block *sb); /* destroy_inode: 销毁alloc_inode分配的索引节点对象，包括相关文件数据空间 */ void (*destroy_inode)(struct inode *); /* free_inode: 释放inode关联的slub高速缓存 */ void (*free_inode)(struct inode *); /* dirty_inode: 将指定的inode标记为脏，表示inode需要被回写 */ void (*dirty_inode) (struct inode *, int flags); /* write_inode: 将inode对象回写到磁盘相应的索引节点中，其中inode-\u0026gt;i_ino * 指出相应的磁盘索引节点号；wbc指示回写时的行为。 */ int (*write_inode) (struct inode *, struct writeback_control *wbc); /* * drop_inode: 最后一个用户释放inode对象后，可用该函数撤销这个inode节点 * 通常这个函数调用generic_drop_inode从VFS数据结构中删除对此inode的引用 */ int (*drop_inode) (struct inode *); void (*evict_inode) (struct inode *); /* put_super: 释放指定的超级块对象(应卸载本超级块指向的文件系统) */ void (*put_super) (struct super_block *); /* sync_fs: 刷新文件系统以更新磁盘文件系统相关的试试数据结构 */ int (*sync_fs)(struct super_block *sb, int wait); int (*freeze_super) (struct super_block *); int (*freeze_fs) (struct super_block *); int (*thaw_super) (struct super_block *); int (*unfreeze_fs) (struct super_block *); /* statfs: 将文件系统的统计信息写入到kstatfs结构指向的buf中 */ int (*statfs) (struct dentry *, struct kstatfs *); /* remount_fs: 使用新的安装标志重新安装/挂载文件系统 */ int (*remount_fs) (struct super_block *, int *, char *); /* umount_begin: 终止当前挂载-因相应的挂载操作已经开始(仅用于网络文件系统) */ void (*umount_begin) (struct super_block *); /* show_options: 显示文件系统相关的选项 */ int (*show_options)(struct seq_file *, struct dentry *); int (*show_devname)(struct seq_file *, struct dentry *); int (*show_path)(struct seq_file *, struct dentry *); int (*show_stats)(struct seq_file *, struct dentry *); #ifdef CONFIG_QUOTA ssize_t (*quota_read)(struct super_block *, int, char *, size_t, loff_t); ssize_t (*quota_write)(struct super_block *, int, const char *, size_t, loff_t); struct dquot **(*get_dquots)(struct inode *); #endif /* nr_cached_objects: 超级块缓存收缩函数调用此函数，返回可释放对象的数量 */ long (*nr_cached_objects)(struct super_block *, struct shrink_control *); /* free_cached_objects: 超级块缓存收缩函数调用此函数，用于扫描可释放对象，并释放它们，此函数必须定义nr_cached_objects函数 */ long (*free_cached_objects)(struct super_block *, struct shrink_control *); }; 对于超级块对象操作函数，有如下几点需要说明：\n超级块对象操作函数是一个通用的抽象，可用于各种文件系统；但是对于特定的文件系统，可以只使用其中的一个子集，不需要的函数指针设置为NULL即可。\n超级块是从磁盘读入的，因此超级块本身的读入方法必须在内存中的超级块建立起来之前就可用，因此超级块的读入函数mount()出现在文件系统类型描述符中，而不是出现在超级块super_block结构体里面。\n参考资料 Linux技术内幕 深入理解Linux内核 https://github.com/freelancer-leon/notes/blob/master/kernel/vfs.md https://www.cnblogs.com/LuoboLiam/tag/linux/ Documentation/filesystems/vfs.rst ","date":"2023-09-15T18:11:10+08:00","permalink":"https://liangxianlong.github.io/post/kernel/fs/vfs%E6%A0%B8%E5%BF%83%E5%AF%B9%E8%B1%A1/","title":"VFS核心对象"},{"content":"可以从用户进程、Linux内核、磁盘三个视角来观察。\n用户进程看待文件:\n按照目录形式命名； 可能随机访问的有序字节集合(无结构)； 具有特定文件属主和文件访问权限； Linux内核看待文件:\n该层是磁盘上各种数据在内核中的动态影像，含文件对象、目录、索引节点、文件数据的页缓存，以及文件系统本身的信息等； 上述所描述的动态影像分为VFS层、具体的文件系统层和通用IO层； 文件在内核中的页缓存也由内核管理； 磁盘文件上的概念:\n包含文件数据的存储格式及其访问规则； 进程中的文件信息 进程的task_struct中与文件系统相关的主要有两个结构体，其中：\nfs_struct主要用于描述进程的根目录(可以和系统根目录不同)和当前目录\nfiles_struct描述当前进程所打开的文件\n1 2 3 4 5 6 7 8 9 struct task_struct { ... /* Filesystem information: */ struct fs_struct *fs; /* Open file information: */ struct files_struct *files; ... }; 进程的文件系统基本信息 fs_struct的定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 struct fs_struct { /*被共享的次数，进程在创建子进程/线程时，可以通过传递的标志控制父子进程是否共享原有 fs_struct*/ int users; spinlock_t lock; seqcount_spinlock_t seq; /*进程创建文件时的默认访问权限*/ int umask; int in_exec; /* * root: 进程使用的根目录(可通过chroot改变默认的根目录，默认使用系统根目录)，root-\u0026gt;dentry； * pwd: 进程使用的当前目录，pwd-\u0026gt;dentry； */ struct path root, pwd; } __randomize_layout; struct path结构体定义如下：\n1 2 3 4 5 6 7 8 9 10 struct path { /* * mnt: path所指向的目录的挂载点信息 */ struct vfsmount *mnt; /* * dentry: path指向的目录的目录项对象 */ struct dentry *dentry; } __randomize_layout; 已打开文件信息 进程所打开的文件记录在进程描述符的files字段，其定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 /* * Open file table structure */ struct files_struct { /* * read mostly part */ /* count: 被(共享)引用的次数，多个进程可以共享同一个files_struct实例(比如多线程) */ atomic_t count; bool resize_in_progress; wait_queue_head_t resize_wait; /* fdt: 初始时指向本结构的fdtab成员 */ struct fdtable __rcu *fdt; /* fdtab: 指向文件描述符表和相关位图 */ struct fdtable fdtab; /* * written part on a separate cache line in SMP */ spinlock_t file_lock ____cacheline_aligned_in_smp; /* next_fd: 下一次打开新文件时使用的文件描述符*/ unsigned int next_fd; /* close_on_exec_init:执行exec时将关闭的文件描述符 */ unsigned long close_on_exec_init[1]; /* open_fds_init:当前进程已打开文件的位图 */ unsigned long open_fds_init[1]; unsigned long full_fds_bits_init[1]; /* * fd_array:记录当前进程打开的所有文件 * 用户进程空间使用文件描述符充当该数组的索引 */ struct file __rcu * fd_array[NR_OPEN_DEFAULT]; }; task_struct-\u0026gt;files字段的作用如下：\n本进程已打开文件的文件描述符； 进程打开的文件描述符和VFS中记录的已打开文件对象之间的联系； 在struct files_struct中有两个重要的成员*fdt和fdtab，其定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 struct fdtable { /* max_fds: 当前进程所能打开的文件数目最大值，可调整 */ unsigned int max_fds; /* fd: 初始时指向当前进程 files_struct-\u0026gt;fd_array[]，进程用户空间使用文件描述符充当fd_array的索引 */ struct file __rcu **fd; /* current fd array */ /* close_on_exec: 初始时指向 files_struct-\u0026gt;close_on_exec_init[]，指定了exec时需要关闭的文件描述符 */ unsigned long *close_on_exec; /* open_fds: 初始时指向 files_struct-\u0026gt;open_fds_init[], 当前进程打开的所 文件描述符 */ unsigned long *open_fds; unsigned long *full_fds_bits; struct rcu_head rcu; }; 因此，整个files_struct的关系如下图所示：\n默认情况下，一个进程能打开的最大文件数量为`NR_OPEN_DEFAULT`(在64位系统上，默认为64)。当进程打开的文件数量超过默认值时，通过`expand_files`函数重新分配一个空间来容纳更多的文件，此时新分配的`fdtable`结构体实例上的三个指针`fd`、`close_on_exec`、`open_fds`将指向新的位置，同时`fdt`指针也指向新分配的`fdtable`实例。参考图1中的扩展前和扩展后。扩展流程如下所述： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 /* * Expand files. * This function will expand the file structures, if the requested size exceeds * the current capacity and there is room for expansion. * Return \u0026lt;0 error code on error; 0 when nothing done; 1 when files were * expanded and execution may have blocked. * The files-\u0026gt;file_lock should be held on entry, and will be held on exit. */ expand_files(struct files_struct *files, unsigned int nr) |——\u0026gt;files_fdtable(files) //获取当前进程的fdt实例 |——\u0026gt;expand_fdtable(files, nr) //扩展fdtable |——\u0026gt;alloc_fdtable(nr) //分配新的fdtable结构体实例 |——\u0026gt;copy_fdtable(new_fdt, cur_fdt) //将原fdtable中的数据拷贝到新的fdtable结构体实例中 |——\u0026gt;rcu_assign_pointer(files-\u0026gt;fdt, new_fdt); //将旧的fdtable实例替换为新的fdtable实例 进程用户空间使用文件描述符(fd)来标识所打开的文件，而内核空间则使用struct file来联系所打开的文件。\nVFS虚拟文件系统 Linux的VFS层屏蔽底层文件系统细节，对整个文件系统做了抽象。在VFS的通用文件模型中需要包含以下对象：\n文件对象(File Object)：存放已打开的文件信息，进程使用文件描述符联系文件对象(见图1)。文件对象仅仅是磁盘静态文件在内存中的动态\u0026quot;户口\u0026quot;，但是并不直接代表文件数据。\n目录项对象(Dentry Object)：存放文件特定识别名与对应文件进行关联的信息，目录项互相间构成了文件系统的树状组织关系。VFS目录项是磁盘上目录信息的一个子集(已访问过的)在内存中的影像。但是需要说明的是目录项对象没有对应的磁盘数据结构。\n索引节点对象(Inode Object)：索引节点的编号可以唯一的标识本文件系统(分区)中的文件，但分属于不同文件系统/分区上的不同文件可以有相同的索引号。索引节点又称为文件控制块，存放对应文件的基本信息——inode号、长度、访问方法和权限等。VFS索引节点是磁盘上的索引节点的内存影像和动态扩展。\n超级块对象(Superblock Object)：存放对应的已安装或者挂载文件系统的基本信息(一个超级块对应多个安装点，如果被同时安装到不同的安装点)，对于磁盘文件系统来说就是磁盘上的文件系统控制块的静态信息加上少量的动态管理信息。VFS超级块对象是磁盘上的超级块在内存中的影像和动态扩展。 总结： 1.索引节点对象inode唯一的代表文件；目录项对象dentry将文件组织成目录树状结构；文件对象file是进程访问文件的接口及现场；超级块对象super_block则记录了整个文件系统的全局性的信息。 2.文件内容和它的管理数据分别称为数据与元数据(元数据在inode中)。inode上的元数据操作涉及整个文件对象-例如创建、删除、链接等；而file文件对象的数据操作则是对文件内容的-读、写、移动文件指针、建立内存映射。 3.文件系统使用磁盘时往往不是用扇区作为最小存储单位，而是使用盘块-若干个连续的扇区为最小单位。但是底层的驱动程序则使用扇区作为访问单位。\n文件系统分层 一般而言文件系统的分层模型如图2所示。\n对文件的操作经过系统调用进入到通用的VFS层统一处理；VFS层根据所使用的缓冲方式，可能经过页缓存快速完成或者跳过页缓存，将请求发送到具体文件系统或块设备上；文件系统或块设备根据这些请求，计算出相应的磁盘盘块号，将请求转给通用块层；通用块层再利用IO调度层将请求合并、调度等优化后向驱动程序发出请求；驱动程序发出的硬件命令由硬盘驱动器执行，然后通过中断逐层向上通知，从而完成一个IO。\n","date":"2023-09-15T16:27:20+08:00","permalink":"https://liangxianlong.github.io/post/kernel/fs/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8A%BD%E8%B1%A1%E5%B1%82%E6%AC%A1/","title":"文件系统的抽象层次"}]